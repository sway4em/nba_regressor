{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, classification_report\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "df = pd.read_csv(\"/content/dataset.csv\")\n",
        "\n",
        "feature_cols = [\n",
        "    'PTS_x', 'REB_x', 'AST_x', 'STL_x', 'BLK_x', 'MIN_x',\n",
        "    'PTS_pg_x', 'REB_pg_x', 'AST_pg_x', 'STL_pg_x', 'BLK_pg_x', 'MIN_pg_x'\n",
        "]\n",
        "\n",
        "X = df[feature_cols]\n",
        "y = df[\"breakout?\"]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "model = XGBClassifier(\n",
        "    n_estimators=200,\n",
        "    learning_rate=0.05,\n",
        "    max_depth=4,\n",
        "    random_state=42,\n",
        "    eval_metric=\"logloss\"\n",
        ")\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "precision = precision_score(y_test, y_pred, zero_division=0)\n",
        "recall = recall_score(y_test, y_pred, zero_division=0)\n",
        "f1 = f1_score(y_test, y_pred, zero_division=0)\n",
        "\n",
        "print(f\"Precision: {precision:.3f}\")\n",
        "print(f\"Recall: {recall:.3f}\")\n",
        "print(f\"F1 Score: {f1:.3f}\")\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3tbMZ4cvQ5bt",
        "outputId": "0ee13550-9ce2-4b2c-e7c3-575e53983b26"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision: 0.512\n",
            "Recall: 0.053\n",
            "F1 Score: 0.096\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.98      0.87      1322\n",
            "           1       0.51      0.05      0.10       396\n",
            "\n",
            "    accuracy                           0.77      1718\n",
            "   macro avg       0.64      0.52      0.48      1718\n",
            "weighted avg       0.72      0.77      0.69      1718\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install catboost"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5FsedmDBTcy0",
        "outputId": "350cb752-e353-44ee-c789-28110de4bd6b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: catboost in /usr/local/lib/python3.12/dist-packages (1.2.8)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.12/dist-packages (from catboost) (0.21)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from catboost) (3.10.0)\n",
            "Requirement already satisfied: numpy<3.0,>=1.16.0 in /usr/local/lib/python3.12/dist-packages (from catboost) (2.0.2)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.12/dist-packages (from catboost) (2.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from catboost) (1.16.3)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.12/dist-packages (from catboost) (5.24.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.12/dist-packages (from catboost) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.24->catboost) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.24->catboost) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.24->catboost) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (3.2.5)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.12/dist-packages (from plotly->catboost) (8.5.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, classification_report\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "df = pd.read_csv(\"/content/dataset.csv\")\n",
        "\n",
        "feature_cols = [\n",
        "    'PTS_x', 'REB_x', 'AST_x', 'STL_x', 'BLK_x', 'MIN_x',\n",
        "    'PTS_pg_x', 'REB_pg_x', 'AST_pg_x', 'STL_pg_x', 'BLK_pg_x', 'MIN_pg_x'\n",
        "]\n",
        "\n",
        "X = df[feature_cols]\n",
        "y = df[\"breakout?\"]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "neg, pos = y_train.value_counts()\n",
        "scale_pos_weight = neg / pos\n",
        "print(f\"scale_pos_weight = {scale_pos_weight:.2f}\")\n",
        "\n",
        "model = XGBClassifier(\n",
        "    n_estimators=600,\n",
        "    learning_rate=0.05,\n",
        "    max_depth=6,\n",
        "    subsample=0.8,\n",
        "    colsample_bytree=0.8,\n",
        "    reg_lambda=1.0,\n",
        "    scale_pos_weight=scale_pos_weight,\n",
        "    random_state=42,\n",
        "    eval_metric='logloss',\n",
        "    use_label_encoder=False\n",
        ")\n",
        "\n",
        "model.fit(\n",
        "    X_train, y_train,\n",
        "    eval_set=[(X_test, y_test)],\n",
        "    verbose=100\n",
        ")\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "precision = precision_score(y_test, y_pred, zero_division=0)\n",
        "recall = recall_score(y_test, y_pred, zero_division=0)\n",
        "f1 = f1_score(y_test, y_pred, zero_division=0)\n",
        "\n",
        "print(f\"Precision: {precision:.3f}\")\n",
        "print(f\"Recall: {recall:.3f}\")\n",
        "print(f\"F1 Score: {f1:.3f}\")\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JPXh5PeXTeM0",
        "outputId": "c524cb7b-727e-4cfd-d16f-18cf5ae40918"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "scale_pos_weight = 3.34\n",
            "[0]\tvalidation_0-logloss:0.68903\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [23:16:38] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[100]\tvalidation_0-logloss:0.61211\n",
            "[200]\tvalidation_0-logloss:0.59590\n",
            "[300]\tvalidation_0-logloss:0.59072\n",
            "[400]\tvalidation_0-logloss:0.58541\n",
            "[500]\tvalidation_0-logloss:0.58407\n",
            "[599]\tvalidation_0-logloss:0.58613\n",
            "Precision: 0.337\n",
            "Recall: 0.323\n",
            "F1 Score: 0.330\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.81      0.80      1322\n",
            "           1       0.34      0.32      0.33       396\n",
            "\n",
            "    accuracy                           0.70      1718\n",
            "   macro avg       0.57      0.57      0.57      1718\n",
            "weighted avg       0.69      0.70      0.70      1718\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, classification_report\n",
        "from xgboost import XGBClassifier\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "df = pd.read_csv(\"/content/dataset.csv\")\n",
        "\n",
        "feature_cols = [\n",
        "    'PTS_x', 'REB_x', 'AST_x', 'STL_x', 'BLK_x', 'MIN_x',\n",
        "    'PTS_pg_x', 'REB_pg_x', 'AST_pg_x', 'STL_pg_x', 'BLK_pg_x', 'MIN_pg_x'\n",
        "]\n",
        "\n",
        "X = df[feature_cols]\n",
        "y = df[\"breakout?\"]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "smote = SMOTE(random_state=42, sampling_strategy='auto', k_neighbors=5)\n",
        "X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "print(f\"Before SMOTE: {y_train.value_counts().to_dict()}\")\n",
        "print(f\"After SMOTE:  {y_train_res.value_counts().to_dict()}\")\n",
        "\n",
        "model = XGBClassifier(\n",
        "    n_estimators=600,\n",
        "    learning_rate=0.05,\n",
        "    max_depth=6,\n",
        "    subsample=0.8,\n",
        "    colsample_bytree=0.8,\n",
        "    reg_lambda=1.0,\n",
        "    random_state=42,\n",
        "    eval_metric='logloss',\n",
        "    use_label_encoder=False\n",
        ")\n",
        "\n",
        "model.fit(\n",
        "    X_train_res, y_train_res,\n",
        "    eval_set=[(X_test, y_test)],\n",
        "    verbose=100\n",
        ")\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "precision = precision_score(y_test, y_pred, zero_division=0)\n",
        "recall = recall_score(y_test, y_pred, zero_division=0)\n",
        "f1 = f1_score(y_test, y_pred, zero_division=0)\n",
        "\n",
        "print(f\"Precision: {precision:.3f}\")\n",
        "print(f\"Recall: {recall:.3f}\")\n",
        "print(f\"F1 Score: {f1:.3f}\")\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jsCHHo-LUOZB",
        "outputId": "a4064f65-56e5-463b-9fb6-3735cf52c6a7"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before SMOTE: {0: 5288, 1: 1581}\n",
            "After SMOTE:  {0: 5288, 1: 5288}\n",
            "[0]\tvalidation_0-logloss:0.68786\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [23:16:46] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[100]\tvalidation_0-logloss:0.62214\n",
            "[200]\tvalidation_0-logloss:0.61671\n",
            "[300]\tvalidation_0-logloss:0.61434\n",
            "[400]\tvalidation_0-logloss:0.61458\n",
            "[500]\tvalidation_0-logloss:0.61607\n",
            "[599]\tvalidation_0-logloss:0.61979\n",
            "Precision: 0.323\n",
            "Recall: 0.434\n",
            "F1 Score: 0.370\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.73      0.77      1322\n",
            "           1       0.32      0.43      0.37       396\n",
            "\n",
            "    accuracy                           0.66      1718\n",
            "   macro avg       0.57      0.58      0.57      1718\n",
            "weighted avg       0.70      0.66      0.68      1718\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold, RandomizedSearchCV\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, classification_report\n",
        "from xgboost import XGBClassifier\n",
        "from imblearn.pipeline import Pipeline\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from scipy.stats import uniform, randint\n",
        "import numpy as np\n",
        "\n",
        "df = pd.read_csv(\"/content/dataset.csv\")\n",
        "\n",
        "feature_cols = [\n",
        "    'PTS_x', 'REB_x', 'AST_x', 'STL_x', 'BLK_x', 'MIN_x',\n",
        "    'PTS_pg_x', 'REB_pg_x', 'AST_pg_x', 'STL_pg_x', 'BLK_pg_x', 'MIN_pg_x'\n",
        "]\n",
        "\n",
        "X = df[feature_cols]\n",
        "y = df[\"breakout?\"]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "pipeline = Pipeline([\n",
        "    ('smote', SMOTE(random_state=42)),\n",
        "    ('xgb', XGBClassifier(\n",
        "        tree_method='hist',\n",
        "        predictor='gpu_predictor',\n",
        "        device='cuda',\n",
        "        use_label_encoder=False,\n",
        "        eval_metric='logloss',\n",
        "        random_state=42\n",
        "    ))\n",
        "])\n",
        "\n",
        "param_distributions = {\n",
        "    'xgb__n_estimators': randint(200, 800),\n",
        "    'xgb__max_depth': randint(3, 10),\n",
        "    'xgb__learning_rate': uniform(0.02, 0.1),\n",
        "    'xgb__subsample': uniform(0.6, 0.4),\n",
        "    'xgb__colsample_bytree': uniform(0.6, 0.4),\n",
        "    'xgb__gamma': uniform(0, 5),\n",
        "    'xgb__reg_lambda': uniform(0.5, 2.0)\n",
        "}\n",
        "\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "search = RandomizedSearchCV(\n",
        "    pipeline,\n",
        "    param_distributions=param_distributions,\n",
        "    n_iter=20,\n",
        "    scoring='f1',\n",
        "    cv=cv,\n",
        "    verbose=2,\n",
        "    n_jobs=1,\n",
        "    random_state=42,\n",
        "    error_score='raise'\n",
        ")\n",
        "\n",
        "try:\n",
        "    search.fit(X_train, y_train)\n",
        "except Exception as e:\n",
        "    raise\n",
        "\n",
        "print(\"\\nBest params:\", search.best_params_)\n",
        "print(f\"Best CV F1: {search.best_score_:.3f}\")\n",
        "\n",
        "best_model = search.best_estimator_\n",
        "y_pred = best_model.predict(X_test)\n",
        "\n",
        "precision = precision_score(y_test, y_pred, zero_division=0)\n",
        "recall = recall_score(y_test, y_pred, zero_division=0)\n",
        "f1 = f1_score(y_test, y_pred, zero_division=0)\n",
        "\n",
        "print(f\"Precision: {precision:.3f}\")\n",
        "print(f\"Recall:    {recall:.3f}\")\n",
        "print(f\"F1 Score:  {f1:.3f}\")\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zZpjELEPUZlS",
        "outputId": "615c1c30-1168-40ef-a272-f5dec6928e06"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [23:16:54] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/core.py:774: UserWarning: [23:16:54] WARNING: /workspace/src/common/error_msg.cc:62: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
            "Potential solutions:\n",
            "- Use a data structure that matches the device ordinal in the booster.\n",
            "- Set the device for booster before call to inplace_predict.\n",
            "\n",
            "This warning will only be shown once.\n",
            "\n",
            "  return func(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END xgb__colsample_bytree=0.749816047538945, xgb__gamma=4.75357153204958, xgb__learning_rate=0.09319939418114051, xgb__max_depth=7, xgb__n_estimators=220, xgb__reg_lambda=0.812037280884873, xgb__subsample=0.662397808134481; total time=   1.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [23:16:55] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END xgb__colsample_bytree=0.749816047538945, xgb__gamma=4.75357153204958, xgb__learning_rate=0.09319939418114051, xgb__max_depth=7, xgb__n_estimators=220, xgb__reg_lambda=0.812037280884873, xgb__subsample=0.662397808134481; total time=   0.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [23:16:55] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END xgb__colsample_bytree=0.749816047538945, xgb__gamma=4.75357153204958, xgb__learning_rate=0.09319939418114051, xgb__max_depth=7, xgb__n_estimators=220, xgb__reg_lambda=0.812037280884873, xgb__subsample=0.662397808134481; total time=   1.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [23:16:57] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END xgb__colsample_bytree=0.749816047538945, xgb__gamma=4.75357153204958, xgb__learning_rate=0.09319939418114051, xgb__max_depth=7, xgb__n_estimators=220, xgb__reg_lambda=0.812037280884873, xgb__subsample=0.662397808134481; total time=   1.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [23:16:58] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END xgb__colsample_bytree=0.749816047538945, xgb__gamma=4.75357153204958, xgb__learning_rate=0.09319939418114051, xgb__max_depth=7, xgb__n_estimators=220, xgb__reg_lambda=0.812037280884873, xgb__subsample=0.662397808134481; total time=   0.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [23:16:58] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END xgb__colsample_bytree=0.6232334448672797, xgb__gamma=4.330880728874676, xgb__learning_rate=0.08011150117432088, xgb__max_depth=5, xgb__n_estimators=508, xgb__reg_lambda=2.4398197043239884, xgb__subsample=0.9329770563201687; total time=   0.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [23:16:59] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END xgb__colsample_bytree=0.6232334448672797, xgb__gamma=4.330880728874676, xgb__learning_rate=0.08011150117432088, xgb__max_depth=5, xgb__n_estimators=508, xgb__reg_lambda=2.4398197043239884, xgb__subsample=0.9329770563201687; total time=   0.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [23:17:00] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END xgb__colsample_bytree=0.6232334448672797, xgb__gamma=4.330880728874676, xgb__learning_rate=0.08011150117432088, xgb__max_depth=5, xgb__n_estimators=508, xgb__reg_lambda=2.4398197043239884, xgb__subsample=0.9329770563201687; total time=   1.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [23:17:01] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END xgb__colsample_bytree=0.6232334448672797, xgb__gamma=4.330880728874676, xgb__learning_rate=0.08011150117432088, xgb__max_depth=5, xgb__n_estimators=508, xgb__reg_lambda=2.4398197043239884, xgb__subsample=0.9329770563201687; total time=   1.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [23:17:02] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END xgb__colsample_bytree=0.6232334448672797, xgb__gamma=4.330880728874676, xgb__learning_rate=0.08011150117432088, xgb__max_depth=5, xgb__n_estimators=508, xgb__reg_lambda=2.4398197043239884, xgb__subsample=0.9329770563201687; total time=   0.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [23:17:03] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END xgb__colsample_bytree=0.6849356442713105, xgb__gamma=0.9091248360355031, xgb__learning_rate=0.03834045098534338, xgb__max_depth=6, xgb__n_estimators=513, xgb__reg_lambda=1.5495128632644757, xgb__subsample=0.7727780074568463; total time=   1.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [23:17:05] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END xgb__colsample_bytree=0.6849356442713105, xgb__gamma=0.9091248360355031, xgb__learning_rate=0.03834045098534338, xgb__max_depth=6, xgb__n_estimators=513, xgb__reg_lambda=1.5495128632644757, xgb__subsample=0.7727780074568463; total time=   1.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [23:17:06] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END xgb__colsample_bytree=0.6849356442713105, xgb__gamma=0.9091248360355031, xgb__learning_rate=0.03834045098534338, xgb__max_depth=6, xgb__n_estimators=513, xgb__reg_lambda=1.5495128632644757, xgb__subsample=0.7727780074568463; total time=   1.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [23:17:08] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END xgb__colsample_bytree=0.6849356442713105, xgb__gamma=0.9091248360355031, xgb__learning_rate=0.03834045098534338, xgb__max_depth=6, xgb__n_estimators=513, xgb__reg_lambda=1.5495128632644757, xgb__subsample=0.7727780074568463; total time=   1.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [23:17:09] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END xgb__colsample_bytree=0.6849356442713105, xgb__gamma=0.9091248360355031, xgb__learning_rate=0.03834045098534338, xgb__max_depth=6, xgb__n_estimators=513, xgb__reg_lambda=1.5495128632644757, xgb__subsample=0.7727780074568463; total time=   1.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [23:17:10] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END xgb__colsample_bytree=0.7164916560792167, xgb__gamma=3.0592644736118975, xgb__learning_rate=0.03394938606520419, xgb__max_depth=6, xgb__n_estimators=389, xgb__reg_lambda=0.6812128690656416, xgb__subsample=0.8473544037332349; total time=   0.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [23:17:10] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END xgb__colsample_bytree=0.7164916560792167, xgb__gamma=3.0592644736118975, xgb__learning_rate=0.03394938606520419, xgb__max_depth=6, xgb__n_estimators=389, xgb__reg_lambda=0.6812128690656416, xgb__subsample=0.8473544037332349; total time=   0.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [23:17:11] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END xgb__colsample_bytree=0.7164916560792167, xgb__gamma=3.0592644736118975, xgb__learning_rate=0.03394938606520419, xgb__max_depth=6, xgb__n_estimators=389, xgb__reg_lambda=0.6812128690656416, xgb__subsample=0.8473544037332349; total time=   0.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [23:17:11] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END xgb__colsample_bytree=0.7164916560792167, xgb__gamma=3.0592644736118975, xgb__learning_rate=0.03394938606520419, xgb__max_depth=6, xgb__n_estimators=389, xgb__reg_lambda=0.6812128690656416, xgb__subsample=0.8473544037332349; total time=   0.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [23:17:11] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END xgb__colsample_bytree=0.7164916560792167, xgb__gamma=3.0592644736118975, xgb__learning_rate=0.03394938606520419, xgb__max_depth=6, xgb__n_estimators=389, xgb__reg_lambda=0.6812128690656416, xgb__subsample=0.8473544037332349; total time=   0.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [23:17:12] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END xgb__colsample_bytree=0.7529847965068651, xgb__gamma=4.916154429033941, xgb__learning_rate=0.066676289324798, xgb__max_depth=7, xgb__n_estimators=220, xgb__reg_lambda=1.400998503939086, xgb__subsample=0.6053059844639466; total time=   0.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [23:17:12] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END xgb__colsample_bytree=0.7529847965068651, xgb__gamma=4.916154429033941, xgb__learning_rate=0.066676289324798, xgb__max_depth=7, xgb__n_estimators=220, xgb__reg_lambda=1.400998503939086, xgb__subsample=0.6053059844639466; total time=   0.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [23:17:12] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END xgb__colsample_bytree=0.7529847965068651, xgb__gamma=4.916154429033941, xgb__learning_rate=0.066676289324798, xgb__max_depth=7, xgb__n_estimators=220, xgb__reg_lambda=1.400998503939086, xgb__subsample=0.6053059844639466; total time=   0.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [23:17:13] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END xgb__colsample_bytree=0.7529847965068651, xgb__gamma=4.916154429033941, xgb__learning_rate=0.066676289324798, xgb__max_depth=7, xgb__n_estimators=220, xgb__reg_lambda=1.400998503939086, xgb__subsample=0.6053059844639466; total time=   0.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [23:17:13] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END xgb__colsample_bytree=0.7529847965068651, xgb__gamma=4.916154429033941, xgb__learning_rate=0.066676289324798, xgb__max_depth=7, xgb__n_estimators=220, xgb__reg_lambda=1.400998503939086, xgb__subsample=0.6053059844639466; total time=   0.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [23:17:13] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END xgb__colsample_bytree=0.9768807022739411, xgb__gamma=2.8164410892276965, xgb__learning_rate=0.05854165025399162, xgb__max_depth=4, xgb__n_estimators=764, xgb__reg_lambda=0.961787651244298, xgb__subsample=0.6964101864104046; total time=   0.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [23:17:14] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END xgb__colsample_bytree=0.9768807022739411, xgb__gamma=2.8164410892276965, xgb__learning_rate=0.05854165025399162, xgb__max_depth=4, xgb__n_estimators=764, xgb__reg_lambda=0.961787651244298, xgb__subsample=0.6964101864104046; total time=   0.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [23:17:15] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END xgb__colsample_bytree=0.9768807022739411, xgb__gamma=2.8164410892276965, xgb__learning_rate=0.05854165025399162, xgb__max_depth=4, xgb__n_estimators=764, xgb__reg_lambda=0.961787651244298, xgb__subsample=0.6964101864104046; total time=   0.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [23:17:15] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END xgb__colsample_bytree=0.9768807022739411, xgb__gamma=2.8164410892276965, xgb__learning_rate=0.05854165025399162, xgb__max_depth=4, xgb__n_estimators=764, xgb__reg_lambda=0.961787651244298, xgb__subsample=0.6964101864104046; total time=   0.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [23:17:16] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END xgb__colsample_bytree=0.9768807022739411, xgb__gamma=2.8164410892276965, xgb__learning_rate=0.05854165025399162, xgb__max_depth=4, xgb__n_estimators=764, xgb__reg_lambda=0.961787651244298, xgb__subsample=0.6964101864104046; total time=   0.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [23:17:17] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END xgb__colsample_bytree=0.8733054075301833, xgb__gamma=3.0499832889131047, xgb__learning_rate=0.10331949117361644, xgb__max_depth=5, xgb__n_estimators=405, xgb__reg_lambda=1.2821212151464816, xgb__subsample=0.672894435115225; total time=   0.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [23:17:17] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END xgb__colsample_bytree=0.8733054075301833, xgb__gamma=3.0499832889131047, xgb__learning_rate=0.10331949117361644, xgb__max_depth=5, xgb__n_estimators=405, xgb__reg_lambda=1.2821212151464816, xgb__subsample=0.672894435115225; total time=   0.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [23:17:17] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END xgb__colsample_bytree=0.8733054075301833, xgb__gamma=3.0499832889131047, xgb__learning_rate=0.10331949117361644, xgb__max_depth=5, xgb__n_estimators=405, xgb__reg_lambda=1.2821212151464816, xgb__subsample=0.672894435115225; total time=   0.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [23:17:18] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END xgb__colsample_bytree=0.8733054075301833, xgb__gamma=3.0499832889131047, xgb__learning_rate=0.10331949117361644, xgb__max_depth=5, xgb__n_estimators=405, xgb__reg_lambda=1.2821212151464816, xgb__subsample=0.672894435115225; total time=   0.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [23:17:18] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END xgb__colsample_bytree=0.8733054075301833, xgb__gamma=3.0499832889131047, xgb__learning_rate=0.10331949117361644, xgb__max_depth=5, xgb__n_estimators=405, xgb__reg_lambda=1.2821212151464816, xgb__subsample=0.672894435115225; total time=   0.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [23:17:19] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END xgb__colsample_bytree=0.902144564127061, xgb__gamma=2.1257793724562237, xgb__learning_rate=0.04079416628681888, xgb__max_depth=6, xgb__n_estimators=676, xgb__reg_lambda=2.439169255529117, xgb__subsample=0.9100531293444458; total time=   0.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [23:17:19] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END xgb__colsample_bytree=0.902144564127061, xgb__gamma=2.1257793724562237, xgb__learning_rate=0.04079416628681888, xgb__max_depth=6, xgb__n_estimators=676, xgb__reg_lambda=2.439169255529117, xgb__subsample=0.9100531293444458; total time=   0.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [23:17:20] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END xgb__colsample_bytree=0.902144564127061, xgb__gamma=2.1257793724562237, xgb__learning_rate=0.04079416628681888, xgb__max_depth=6, xgb__n_estimators=676, xgb__reg_lambda=2.439169255529117, xgb__subsample=0.9100531293444458; total time=   0.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [23:17:21] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END xgb__colsample_bytree=0.902144564127061, xgb__gamma=2.1257793724562237, xgb__learning_rate=0.04079416628681888, xgb__max_depth=6, xgb__n_estimators=676, xgb__reg_lambda=2.439169255529117, xgb__subsample=0.9100531293444458; total time=   0.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [23:17:22] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END xgb__colsample_bytree=0.902144564127061, xgb__gamma=2.1257793724562237, xgb__learning_rate=0.04079416628681888, xgb__max_depth=6, xgb__n_estimators=676, xgb__reg_lambda=2.439169255529117, xgb__subsample=0.9100531293444458; total time=   0.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [23:17:22] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END xgb__colsample_bytree=0.9757995766256756, xgb__gamma=4.474136752138244, xgb__learning_rate=0.07978999788110852, xgb__max_depth=9, xgb__n_estimators=655, xgb__reg_lambda=1.6408879488107988, xgb__subsample=0.8083337040103294; total time=   0.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [23:17:23] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END xgb__colsample_bytree=0.9757995766256756, xgb__gamma=4.474136752138244, xgb__learning_rate=0.07978999788110852, xgb__max_depth=9, xgb__n_estimators=655, xgb__reg_lambda=1.6408879488107988, xgb__subsample=0.8083337040103294; total time=   0.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [23:17:23] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END xgb__colsample_bytree=0.9757995766256756, xgb__gamma=4.474136752138244, xgb__learning_rate=0.07978999788110852, xgb__max_depth=9, xgb__n_estimators=655, xgb__reg_lambda=1.6408879488107988, xgb__subsample=0.8083337040103294; total time=   0.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [23:17:24] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END xgb__colsample_bytree=0.9757995766256756, xgb__gamma=4.474136752138244, xgb__learning_rate=0.07978999788110852, xgb__max_depth=9, xgb__n_estimators=655, xgb__reg_lambda=1.6408879488107988, xgb__subsample=0.8083337040103294; total time=   0.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [23:17:24] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END xgb__colsample_bytree=0.9757995766256756, xgb__gamma=4.474136752138244, xgb__learning_rate=0.07978999788110852, xgb__max_depth=9, xgb__n_estimators=655, xgb__reg_lambda=1.6408879488107988, xgb__subsample=0.8083337040103294; total time=   0.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [23:17:25] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END xgb__colsample_bytree=0.9844688097397396, xgb__gamma=4.222669243390757, xgb__learning_rate=0.0947320110137381, xgb__max_depth=9, xgb__n_estimators=252, xgb__reg_lambda=1.6735023313276964, xgb__subsample=0.9861021229056552; total time=   0.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [23:17:25] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END xgb__colsample_bytree=0.9844688097397396, xgb__gamma=4.222669243390757, xgb__learning_rate=0.0947320110137381, xgb__max_depth=9, xgb__n_estimators=252, xgb__reg_lambda=1.6735023313276964, xgb__subsample=0.9861021229056552; total time=   0.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [23:17:25] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END xgb__colsample_bytree=0.9844688097397396, xgb__gamma=4.222669243390757, xgb__learning_rate=0.0947320110137381, xgb__max_depth=9, xgb__n_estimators=252, xgb__reg_lambda=1.6735023313276964, xgb__subsample=0.9861021229056552; total time=   0.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [23:17:26] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END xgb__colsample_bytree=0.9844688097397396, xgb__gamma=4.222669243390757, xgb__learning_rate=0.0947320110137381, xgb__max_depth=9, xgb__n_estimators=252, xgb__reg_lambda=1.6735023313276964, xgb__subsample=0.9861021229056552; total time=   0.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [23:17:26] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END xgb__colsample_bytree=0.9844688097397396, xgb__gamma=4.222669243390757, xgb__learning_rate=0.0947320110137381, xgb__max_depth=9, xgb__n_estimators=252, xgb__reg_lambda=1.6735023313276964, xgb__subsample=0.9861021229056552; total time=   0.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [23:17:26] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END xgb__colsample_bytree=0.8428136990746738, xgb__gamma=1.3799959101127168, xgb__learning_rate=0.04962735057040824, xgb__max_depth=7, xgb__n_estimators=264, xgb__reg_lambda=0.5312728134823879, xgb__subsample=0.7693605922825478; total time=   0.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [23:17:27] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END xgb__colsample_bytree=0.8428136990746738, xgb__gamma=1.3799959101127168, xgb__learning_rate=0.04962735057040824, xgb__max_depth=7, xgb__n_estimators=264, xgb__reg_lambda=0.5312728134823879, xgb__subsample=0.7693605922825478; total time=   0.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [23:17:27] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END xgb__colsample_bytree=0.8428136990746738, xgb__gamma=1.3799959101127168, xgb__learning_rate=0.04962735057040824, xgb__max_depth=7, xgb__n_estimators=264, xgb__reg_lambda=0.5312728134823879, xgb__subsample=0.7693605922825478; total time=   0.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [23:17:28] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END xgb__colsample_bytree=0.8428136990746738, xgb__gamma=1.3799959101127168, xgb__learning_rate=0.04962735057040824, xgb__max_depth=7, xgb__n_estimators=264, xgb__reg_lambda=0.5312728134823879, xgb__subsample=0.7693605922825478; total time=   0.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [23:17:28] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END xgb__colsample_bytree=0.8428136990746738, xgb__gamma=1.3799959101127168, xgb__learning_rate=0.04962735057040824, xgb__max_depth=7, xgb__n_estimators=264, xgb__reg_lambda=0.5312728134823879, xgb__subsample=0.7693605922825478; total time=   0.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [23:17:29] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END xgb__colsample_bytree=0.7579526072702278, xgb__gamma=1.4674408735901907, xgb__learning_rate=0.021407982271508447, xgb__max_depth=5, xgb__n_estimators=792, xgb__reg_lambda=1.9226839054973, xgb__subsample=0.9160702162124823; total time=   0.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [23:17:30] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END xgb__colsample_bytree=0.7579526072702278, xgb__gamma=1.4674408735901907, xgb__learning_rate=0.021407982271508447, xgb__max_depth=5, xgb__n_estimators=792, xgb__reg_lambda=1.9226839054973, xgb__subsample=0.9160702162124823; total time=   0.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [23:17:31] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END xgb__colsample_bytree=0.7579526072702278, xgb__gamma=1.4674408735901907, xgb__learning_rate=0.021407982271508447, xgb__max_depth=5, xgb__n_estimators=792, xgb__reg_lambda=1.9226839054973, xgb__subsample=0.9160702162124823; total time=   0.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [23:17:32] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END xgb__colsample_bytree=0.7579526072702278, xgb__gamma=1.4674408735901907, xgb__learning_rate=0.021407982271508447, xgb__max_depth=5, xgb__n_estimators=792, xgb__reg_lambda=1.9226839054973, xgb__subsample=0.9160702162124823; total time=   1.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [23:17:33] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END xgb__colsample_bytree=0.7579526072702278, xgb__gamma=1.4674408735901907, xgb__learning_rate=0.021407982271508447, xgb__max_depth=5, xgb__n_estimators=792, xgb__reg_lambda=1.9226839054973, xgb__subsample=0.9160702162124823; total time=   1.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [23:17:34] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END xgb__colsample_bytree=0.8423839899124046, xgb__gamma=4.631504392566745, xgb__learning_rate=0.08510770255019445, xgb__max_depth=6, xgb__n_estimators=334, xgb__reg_lambda=2.2000771555795984, xgb__subsample=0.7797802696552814; total time=   0.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [23:17:34] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END xgb__colsample_bytree=0.8423839899124046, xgb__gamma=4.631504392566745, xgb__learning_rate=0.08510770255019445, xgb__max_depth=6, xgb__n_estimators=334, xgb__reg_lambda=2.2000771555795984, xgb__subsample=0.7797802696552814; total time=   0.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [23:17:34] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END xgb__colsample_bytree=0.8423839899124046, xgb__gamma=4.631504392566745, xgb__learning_rate=0.08510770255019445, xgb__max_depth=6, xgb__n_estimators=334, xgb__reg_lambda=2.2000771555795984, xgb__subsample=0.7797802696552814; total time=   0.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [23:17:35] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END xgb__colsample_bytree=0.8423839899124046, xgb__gamma=4.631504392566745, xgb__learning_rate=0.08510770255019445, xgb__max_depth=6, xgb__n_estimators=334, xgb__reg_lambda=2.2000771555795984, xgb__subsample=0.7797802696552814; total time=   0.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [23:17:35] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END xgb__colsample_bytree=0.8423839899124046, xgb__gamma=4.631504392566745, xgb__learning_rate=0.08510770255019445, xgb__max_depth=6, xgb__n_estimators=334, xgb__reg_lambda=2.2000771555795984, xgb__subsample=0.7797802696552814; total time=   0.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [23:17:35] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END xgb__colsample_bytree=0.6381640465961645, xgb__gamma=1.8540912609913318, xgb__learning_rate=0.08688412526636073, xgb__max_depth=7, xgb__n_estimators=298, xgb__reg_lambda=1.6825955754154542, xgb__subsample=0.7098887171960256; total time=   0.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [23:17:36] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END xgb__colsample_bytree=0.6381640465961645, xgb__gamma=1.8540912609913318, xgb__learning_rate=0.08688412526636073, xgb__max_depth=7, xgb__n_estimators=298, xgb__reg_lambda=1.6825955754154542, xgb__subsample=0.7098887171960256; total time=   0.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [23:17:36] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END xgb__colsample_bytree=0.6381640465961645, xgb__gamma=1.8540912609913318, xgb__learning_rate=0.08688412526636073, xgb__max_depth=7, xgb__n_estimators=298, xgb__reg_lambda=1.6825955754154542, xgb__subsample=0.7098887171960256; total time=   0.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [23:17:37] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END xgb__colsample_bytree=0.6381640465961645, xgb__gamma=1.8540912609913318, xgb__learning_rate=0.08688412526636073, xgb__max_depth=7, xgb__n_estimators=298, xgb__reg_lambda=1.6825955754154542, xgb__subsample=0.7098887171960256; total time=   0.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [23:17:37] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END xgb__colsample_bytree=0.6381640465961645, xgb__gamma=1.8540912609913318, xgb__learning_rate=0.08688412526636073, xgb__max_depth=7, xgb__n_estimators=298, xgb__reg_lambda=1.6825955754154542, xgb__subsample=0.7098887171960256; total time=   0.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [23:17:38] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END xgb__colsample_bytree=0.8244973703390804, xgb__gamma=1.914634373768949, xgb__learning_rate=0.11717120953891039, xgb__max_depth=5, xgb__n_estimators=204, xgb__reg_lambda=1.6225543951389925, xgb__subsample=0.9083868719818244; total time=   0.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [23:17:38] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END xgb__colsample_bytree=0.8244973703390804, xgb__gamma=1.914634373768949, xgb__learning_rate=0.11717120953891039, xgb__max_depth=5, xgb__n_estimators=204, xgb__reg_lambda=1.6225543951389925, xgb__subsample=0.9083868719818244; total time=   0.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [23:17:38] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END xgb__colsample_bytree=0.8244973703390804, xgb__gamma=1.914634373768949, xgb__learning_rate=0.11717120953891039, xgb__max_depth=5, xgb__n_estimators=204, xgb__reg_lambda=1.6225543951389925, xgb__subsample=0.9083868719818244; total time=   0.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [23:17:38] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END xgb__colsample_bytree=0.8244973703390804, xgb__gamma=1.914634373768949, xgb__learning_rate=0.11717120953891039, xgb__max_depth=5, xgb__n_estimators=204, xgb__reg_lambda=1.6225543951389925, xgb__subsample=0.9083868719818244; total time=   0.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [23:17:39] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END xgb__colsample_bytree=0.8244973703390804, xgb__gamma=1.914634373768949, xgb__learning_rate=0.11717120953891039, xgb__max_depth=5, xgb__n_estimators=204, xgb__reg_lambda=1.6225543951389925, xgb__subsample=0.9083868719818244; total time=   0.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [23:17:39] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END xgb__colsample_bytree=0.7975182385457563, xgb__gamma=2.6136641469099704, xgb__learning_rate=0.06275410183585496, xgb__max_depth=4, xgb__n_estimators=660, xgb__reg_lambda=0.9034384046707924, xgb__subsample=0.9583054382694077; total time=   0.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [23:17:39] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END xgb__colsample_bytree=0.7975182385457563, xgb__gamma=2.6136641469099704, xgb__learning_rate=0.06275410183585496, xgb__max_depth=4, xgb__n_estimators=660, xgb__reg_lambda=0.9034384046707924, xgb__subsample=0.9583054382694077; total time=   0.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [23:17:40] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END xgb__colsample_bytree=0.7975182385457563, xgb__gamma=2.6136641469099704, xgb__learning_rate=0.06275410183585496, xgb__max_depth=4, xgb__n_estimators=660, xgb__reg_lambda=0.9034384046707924, xgb__subsample=0.9583054382694077; total time=   0.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [23:17:40] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END xgb__colsample_bytree=0.7975182385457563, xgb__gamma=2.6136641469099704, xgb__learning_rate=0.06275410183585496, xgb__max_depth=4, xgb__n_estimators=660, xgb__reg_lambda=0.9034384046707924, xgb__subsample=0.9583054382694077; total time=   0.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [23:17:41] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END xgb__colsample_bytree=0.7975182385457563, xgb__gamma=2.6136641469099704, xgb__learning_rate=0.06275410183585496, xgb__max_depth=4, xgb__n_estimators=660, xgb__reg_lambda=0.9034384046707924, xgb__subsample=0.9583054382694077; total time=   0.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [23:17:41] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END xgb__colsample_bytree=0.7901480892728447, xgb__gamma=2.8163778598819182, xgb__learning_rate=0.08955160864261276, xgb__max_depth=7, xgb__n_estimators=606, xgb__reg_lambda=1.7088347585556345, xgb__subsample=0.8159364365206693; total time=   0.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [23:17:42] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END xgb__colsample_bytree=0.7901480892728447, xgb__gamma=2.8163778598819182, xgb__learning_rate=0.08955160864261276, xgb__max_depth=7, xgb__n_estimators=606, xgb__reg_lambda=1.7088347585556345, xgb__subsample=0.8159364365206693; total time=   0.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [23:17:42] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END xgb__colsample_bytree=0.7901480892728447, xgb__gamma=2.8163778598819182, xgb__learning_rate=0.08955160864261276, xgb__max_depth=7, xgb__n_estimators=606, xgb__reg_lambda=1.7088347585556345, xgb__subsample=0.8159364365206693; total time=   0.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [23:17:43] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END xgb__colsample_bytree=0.7901480892728447, xgb__gamma=2.8163778598819182, xgb__learning_rate=0.08955160864261276, xgb__max_depth=7, xgb__n_estimators=606, xgb__reg_lambda=1.7088347585556345, xgb__subsample=0.8159364365206693; total time=   0.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [23:17:43] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END xgb__colsample_bytree=0.7901480892728447, xgb__gamma=2.8163778598819182, xgb__learning_rate=0.08955160864261276, xgb__max_depth=7, xgb__n_estimators=606, xgb__reg_lambda=1.7088347585556345, xgb__subsample=0.8159364365206693; total time=   0.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [23:17:44] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END xgb__colsample_bytree=0.6812244898939077, xgb__gamma=4.714267852789905, xgb__learning_rate=0.0798865466488536, xgb__max_depth=5, xgb__n_estimators=285, xgb__reg_lambda=2.260935678030515, xgb__subsample=0.8497416192535173; total time=   0.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [23:17:44] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END xgb__colsample_bytree=0.6812244898939077, xgb__gamma=4.714267852789905, xgb__learning_rate=0.0798865466488536, xgb__max_depth=5, xgb__n_estimators=285, xgb__reg_lambda=2.260935678030515, xgb__subsample=0.8497416192535173; total time=   0.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [23:17:44] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END xgb__colsample_bytree=0.6812244898939077, xgb__gamma=4.714267852789905, xgb__learning_rate=0.0798865466488536, xgb__max_depth=5, xgb__n_estimators=285, xgb__reg_lambda=2.260935678030515, xgb__subsample=0.8497416192535173; total time=   0.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [23:17:44] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END xgb__colsample_bytree=0.6812244898939077, xgb__gamma=4.714267852789905, xgb__learning_rate=0.0798865466488536, xgb__max_depth=5, xgb__n_estimators=285, xgb__reg_lambda=2.260935678030515, xgb__subsample=0.8497416192535173; total time=   0.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [23:17:45] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END xgb__colsample_bytree=0.6812244898939077, xgb__gamma=4.714267852789905, xgb__learning_rate=0.0798865466488536, xgb__max_depth=5, xgb__n_estimators=285, xgb__reg_lambda=2.260935678030515, xgb__subsample=0.8497416192535173; total time=   0.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [23:17:45] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END xgb__colsample_bytree=0.7182534743350856, xgb__gamma=0.527471299151353, xgb__learning_rate=0.06565345704829102, xgb__max_depth=6, xgb__n_estimators=755, xgb__reg_lambda=1.3330198957407324, xgb__subsample=0.9533121035675474; total time=   1.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [23:17:46] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END xgb__colsample_bytree=0.7182534743350856, xgb__gamma=0.527471299151353, xgb__learning_rate=0.06565345704829102, xgb__max_depth=6, xgb__n_estimators=755, xgb__reg_lambda=1.3330198957407324, xgb__subsample=0.9533121035675474; total time=   1.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [23:17:47] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END xgb__colsample_bytree=0.7182534743350856, xgb__gamma=0.527471299151353, xgb__learning_rate=0.06565345704829102, xgb__max_depth=6, xgb__n_estimators=755, xgb__reg_lambda=1.3330198957407324, xgb__subsample=0.9533121035675474; total time=   0.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [23:17:48] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END xgb__colsample_bytree=0.7182534743350856, xgb__gamma=0.527471299151353, xgb__learning_rate=0.06565345704829102, xgb__max_depth=6, xgb__n_estimators=755, xgb__reg_lambda=1.3330198957407324, xgb__subsample=0.9533121035675474; total time=   0.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [23:17:49] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END xgb__colsample_bytree=0.7182534743350856, xgb__gamma=0.527471299151353, xgb__learning_rate=0.06565345704829102, xgb__max_depth=6, xgb__n_estimators=755, xgb__reg_lambda=1.3330198957407324, xgb__subsample=0.9533121035675474; total time=   0.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [23:17:50] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END xgb__colsample_bytree=0.7297380084021096, xgb__gamma=0.6104397735033668, xgb__learning_rate=0.055629783807697494, xgb__max_depth=8, xgb__n_estimators=424, xgb__reg_lambda=1.0442644987692706, xgb__subsample=0.8590760482165449; total time=   0.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [23:17:51] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END xgb__colsample_bytree=0.7297380084021096, xgb__gamma=0.6104397735033668, xgb__learning_rate=0.055629783807697494, xgb__max_depth=8, xgb__n_estimators=424, xgb__reg_lambda=1.0442644987692706, xgb__subsample=0.8590760482165449; total time=   0.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [23:17:52] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END xgb__colsample_bytree=0.7297380084021096, xgb__gamma=0.6104397735033668, xgb__learning_rate=0.055629783807697494, xgb__max_depth=8, xgb__n_estimators=424, xgb__reg_lambda=1.0442644987692706, xgb__subsample=0.8590760482165449; total time=   0.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [23:17:53] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END xgb__colsample_bytree=0.7297380084021096, xgb__gamma=0.6104397735033668, xgb__learning_rate=0.055629783807697494, xgb__max_depth=8, xgb__n_estimators=424, xgb__reg_lambda=1.0442644987692706, xgb__subsample=0.8590760482165449; total time=   0.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [23:17:53] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END xgb__colsample_bytree=0.7297380084021096, xgb__gamma=0.6104397735033668, xgb__learning_rate=0.055629783807697494, xgb__max_depth=8, xgb__n_estimators=424, xgb__reg_lambda=1.0442644987692706, xgb__subsample=0.8590760482165449; total time=   0.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [23:17:54] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Best params: {'xgb__colsample_bytree': np.float64(0.6812244898939077), 'xgb__gamma': np.float64(4.714267852789905), 'xgb__learning_rate': np.float64(0.0798865466488536), 'xgb__max_depth': 5, 'xgb__n_estimators': 285, 'xgb__reg_lambda': np.float64(2.260935678030515), 'xgb__subsample': np.float64(0.8497416192535173)}\n",
            "Best CV F1: 0.405\n",
            "Precision: 0.318\n",
            "Recall:    0.593\n",
            "F1 Score:  0.414\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.62      0.71      1322\n",
            "           1       0.32      0.59      0.41       396\n",
            "\n",
            "    accuracy                           0.61      1718\n",
            "   macro avg       0.58      0.61      0.56      1718\n",
            "weighted avg       0.72      0.61      0.64      1718\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold, RandomizedSearchCV\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, classification_report, precision_recall_curve\n",
        "from xgboost import XGBClassifier\n",
        "from imblearn.pipeline import Pipeline\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from scipy.stats import uniform, randint\n",
        "import xgboost as xgb\n",
        "\n",
        "df = pd.read_csv(\"/content/dataset.csv\")\n",
        "\n",
        "feature_cols = [\n",
        "    'PTS_x','REB_x','AST_x','STL_x','BLK_x','MIN_x',\n",
        "    'PTS_pg_x','REB_pg_x','AST_pg_x','STL_pg_x','BLK_pg_x','MIN_pg_x'\n",
        "]\n",
        "X = df[feature_cols]\n",
        "y = df[\"breakout?\"].astype(int)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "\n",
        "gpu_params = dict(tree_method=\"hist\", predictor=\"gpu_predictor\", device=\"cuda\")\n",
        "\n",
        "base_xgb = XGBClassifier(\n",
        "    **gpu_params,\n",
        "    eval_metric=\"logloss\",\n",
        "    random_state=42,\n",
        "    use_label_encoder=False\n",
        ")\n",
        "\n",
        "pipe = Pipeline([\n",
        "    (\"smote\", SMOTE(random_state=42)),\n",
        "    (\"xgb\", base_xgb)\n",
        "])\n",
        "\n",
        "param_distributions = {\n",
        "    \"xgb__n_estimators\": randint(300, 900),\n",
        "    \"xgb__max_depth\": randint(3, 10),\n",
        "    \"xgb__learning_rate\": uniform(0.02, 0.1),\n",
        "    \"xgb__subsample\": uniform(0.6, 0.4),\n",
        "    \"xgb__colsample_bytree\": uniform(0.6, 0.4),\n",
        "    \"xgb__gamma\": uniform(0, 5),\n",
        "    \"xgb__min_child_weight\": randint(1, 10),\n",
        "    \"xgb__reg_lambda\": uniform(0.5, 2),\n",
        "    \"xgb__reg_alpha\": uniform(0, 1),\n",
        "}\n",
        "\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "search = RandomizedSearchCV(\n",
        "    estimator=pipe,\n",
        "    param_distributions=param_distributions,\n",
        "    n_iter=30,\n",
        "    scoring=\"f1\",\n",
        "    cv=cv,\n",
        "    verbose=2,\n",
        "    n_jobs=1,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "search.fit(X_train, y_train)\n",
        "print(\"\\nBest parameters:\", search.best_params_)\n",
        "print(f\"Best CV F1: {search.best_score_:.4f}\")\n",
        "\n",
        "\n",
        "best_params = {k.replace(\"xgb__\", \"\"): v for k, v in search.best_params_.items() if k.startswith(\"xgb__\")}\n",
        "params = {\n",
        "    **best_params,\n",
        "    **gpu_params,\n",
        "    \"eval_metric\": \"logloss\",\n",
        "    \"random_state\": 42\n",
        "}\n",
        "\n",
        "X_tr, X_val, y_tr, y_val = train_test_split(\n",
        "    X_train, y_train, test_size=0.2, random_state=42, stratify=y_train\n",
        ")\n",
        "\n",
        "smote = SMOTE(random_state=42)\n",
        "X_tr_res, y_tr_res = smote.fit_resample(X_tr, y_tr)\n",
        "\n",
        "dtrain = xgb.DMatrix(X_tr_res, label=y_tr_res)\n",
        "dval   = xgb.DMatrix(X_val, label=y_val)\n",
        "\n",
        "num_boost_round = int(best_params.get(\"n_estimators\", 600))\n",
        "booster = xgb.train(\n",
        "    params=params,\n",
        "    dtrain=dtrain,\n",
        "    num_boost_round=num_boost_round,\n",
        "    evals=[(dval, \"validation\")],\n",
        "    early_stopping_rounds=50,\n",
        "    verbose_eval=False\n",
        ")\n",
        "\n",
        "final_xgb = XGBClassifier(**params)\n",
        "final_xgb._Booster = booster\n",
        "final_xgb.n_estimators = booster.best_iteration\n",
        "\n",
        "\n",
        "y_val_prob = booster.predict(dval)\n",
        "prec, rec, thresh = precision_recall_curve(y_val, y_val_prob)\n",
        "f1_scores = 2 * (prec * rec) / (prec + rec + 1e-12)\n",
        "best_idx = np.nanargmax(f1_scores)\n",
        "best_thresh = float(thresh[max(best_idx, 0)]) if len(thresh) > 0 else 0.5\n",
        "print(f\"\\nBest threshold for F1 (validation): {best_thresh:.4f}\")\n",
        "print(f\"Val Precision/Recall/F1: {prec[best_idx]:.3f}/{rec[best_idx]:.3f}/{f1_scores[best_idx]:.3f}\")\n",
        "\n",
        "\n",
        "dtest = xgb.DMatrix(X_test)\n",
        "y_test_prob = booster.predict(dtest)\n",
        "y_test_pred = (y_test_prob >= best_thresh).astype(int)\n",
        "\n",
        "precision = precision_score(y_test, y_test_pred, zero_division=0)\n",
        "recall    = recall_score(y_test, y_test_pred, zero_division=0)\n",
        "f1        = f1_score(y_test, y_test_pred, zero_division=0)\n",
        "\n",
        "print(f\"Precision: {precision:.3f}\")\n",
        "print(f\"Recall:    {recall:.3f}\")\n",
        "print(f\"F1 Score:  {f1:.3f}\")\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_test_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "55LuafHMVwBt",
        "outputId": "f7036595-c838-455a-83fe-1020e1dcd60d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
            "[CV] END xgb__colsample_bytree=0.749816047538945, xgb__gamma=4.75357153204958, xgb__learning_rate=0.09319939418114051, xgb__max_depth=7, xgb__min_child_weight=5, xgb__n_estimators=421, xgb__reg_alpha=0.15599452033620265, xgb__reg_lambda=0.6161672243363989, xgb__subsample=0.9464704583099741; total time=   0.3s\n",
            "[CV] END xgb__colsample_bytree=0.749816047538945, xgb__gamma=4.75357153204958, xgb__learning_rate=0.09319939418114051, xgb__max_depth=7, xgb__min_child_weight=5, xgb__n_estimators=421, xgb__reg_alpha=0.15599452033620265, xgb__reg_lambda=0.6161672243363989, xgb__subsample=0.9464704583099741; total time=   0.3s\n",
            "[CV] END xgb__colsample_bytree=0.749816047538945, xgb__gamma=4.75357153204958, xgb__learning_rate=0.09319939418114051, xgb__max_depth=7, xgb__min_child_weight=5, xgb__n_estimators=421, xgb__reg_alpha=0.15599452033620265, xgb__reg_lambda=0.6161672243363989, xgb__subsample=0.9464704583099741; total time=   0.3s\n",
            "[CV] END xgb__colsample_bytree=0.749816047538945, xgb__gamma=4.75357153204958, xgb__learning_rate=0.09319939418114051, xgb__max_depth=7, xgb__min_child_weight=5, xgb__n_estimators=421, xgb__reg_alpha=0.15599452033620265, xgb__reg_lambda=0.6161672243363989, xgb__subsample=0.9464704583099741; total time=   0.3s\n",
            "[CV] END xgb__colsample_bytree=0.749816047538945, xgb__gamma=4.75357153204958, xgb__learning_rate=0.09319939418114051, xgb__max_depth=7, xgb__min_child_weight=5, xgb__n_estimators=421, xgb__reg_alpha=0.15599452033620265, xgb__reg_lambda=0.6161672243363989, xgb__subsample=0.9464704583099741; total time=   0.3s\n",
            "[CV] END xgb__colsample_bytree=0.8404460046972835, xgb__gamma=3.540362888980227, xgb__learning_rate=0.022058449429580244, xgb__max_depth=4, xgb__min_child_weight=8, xgb__n_estimators=791, xgb__reg_alpha=0.9385527090157502, xgb__reg_lambda=0.5015575316820287, xgb__subsample=0.996884623716487; total time=   0.8s\n",
            "[CV] END xgb__colsample_bytree=0.8404460046972835, xgb__gamma=3.540362888980227, xgb__learning_rate=0.022058449429580244, xgb__max_depth=4, xgb__min_child_weight=8, xgb__n_estimators=791, xgb__reg_alpha=0.9385527090157502, xgb__reg_lambda=0.5015575316820287, xgb__subsample=0.996884623716487; total time=   0.8s\n",
            "[CV] END xgb__colsample_bytree=0.8404460046972835, xgb__gamma=3.540362888980227, xgb__learning_rate=0.022058449429580244, xgb__max_depth=4, xgb__min_child_weight=8, xgb__n_estimators=791, xgb__reg_alpha=0.9385527090157502, xgb__reg_lambda=0.5015575316820287, xgb__subsample=0.996884623716487; total time=   0.8s\n",
            "[CV] END xgb__colsample_bytree=0.8404460046972835, xgb__gamma=3.540362888980227, xgb__learning_rate=0.022058449429580244, xgb__max_depth=4, xgb__min_child_weight=8, xgb__n_estimators=791, xgb__reg_alpha=0.9385527090157502, xgb__reg_lambda=0.5015575316820287, xgb__subsample=0.996884623716487; total time=   0.6s\n",
            "[CV] END xgb__colsample_bytree=0.8404460046972835, xgb__gamma=3.540362888980227, xgb__learning_rate=0.022058449429580244, xgb__max_depth=4, xgb__min_child_weight=8, xgb__n_estimators=791, xgb__reg_alpha=0.9385527090157502, xgb__reg_lambda=0.5015575316820287, xgb__subsample=0.996884623716487; total time=   0.6s\n",
            "[CV] END xgb__colsample_bytree=0.8469926038510867, xgb__gamma=3.0582658024414044, xgb__learning_rate=0.02070663052197174, xgb__max_depth=3, xgb__min_child_weight=1, xgb__n_estimators=774, xgb__reg_alpha=0.6118528947223795, xgb__reg_lambda=0.7789877213040837, xgb__subsample=0.7168578594140873; total time=   0.7s\n",
            "[CV] END xgb__colsample_bytree=0.8469926038510867, xgb__gamma=3.0582658024414044, xgb__learning_rate=0.02070663052197174, xgb__max_depth=3, xgb__min_child_weight=1, xgb__n_estimators=774, xgb__reg_alpha=0.6118528947223795, xgb__reg_lambda=0.7789877213040837, xgb__subsample=0.7168578594140873; total time=   0.7s\n",
            "[CV] END xgb__colsample_bytree=0.8469926038510867, xgb__gamma=3.0582658024414044, xgb__learning_rate=0.02070663052197174, xgb__max_depth=3, xgb__min_child_weight=1, xgb__n_estimators=774, xgb__reg_alpha=0.6118528947223795, xgb__reg_lambda=0.7789877213040837, xgb__subsample=0.7168578594140873; total time=   0.7s\n",
            "[CV] END xgb__colsample_bytree=0.8469926038510867, xgb__gamma=3.0582658024414044, xgb__learning_rate=0.02070663052197174, xgb__max_depth=3, xgb__min_child_weight=1, xgb__n_estimators=774, xgb__reg_alpha=0.6118528947223795, xgb__reg_lambda=0.7789877213040837, xgb__subsample=0.7168578594140873; total time=   0.7s\n",
            "[CV] END xgb__colsample_bytree=0.8469926038510867, xgb__gamma=3.0582658024414044, xgb__learning_rate=0.02070663052197174, xgb__max_depth=3, xgb__min_child_weight=1, xgb__n_estimators=774, xgb__reg_alpha=0.6118528947223795, xgb__reg_lambda=0.7789877213040837, xgb__subsample=0.7168578594140873; total time=   0.7s\n",
            "[CV] END xgb__colsample_bytree=0.7465447373174767, xgb__gamma=2.28034992108518, xgb__learning_rate=0.09851759613930137, xgb__max_depth=5, xgb__min_child_weight=7, xgb__n_estimators=543, xgb__reg_alpha=0.5924145688620425, xgb__reg_lambda=0.5929008254399954, xgb__subsample=0.8430179407605753; total time=   0.5s\n",
            "[CV] END xgb__colsample_bytree=0.7465447373174767, xgb__gamma=2.28034992108518, xgb__learning_rate=0.09851759613930137, xgb__max_depth=5, xgb__min_child_weight=7, xgb__n_estimators=543, xgb__reg_alpha=0.5924145688620425, xgb__reg_lambda=0.5929008254399954, xgb__subsample=0.8430179407605753; total time=   0.5s\n",
            "[CV] END xgb__colsample_bytree=0.7465447373174767, xgb__gamma=2.28034992108518, xgb__learning_rate=0.09851759613930137, xgb__max_depth=5, xgb__min_child_weight=7, xgb__n_estimators=543, xgb__reg_alpha=0.5924145688620425, xgb__reg_lambda=0.5929008254399954, xgb__subsample=0.8430179407605753; total time=   0.5s\n",
            "[CV] END xgb__colsample_bytree=0.7465447373174767, xgb__gamma=2.28034992108518, xgb__learning_rate=0.09851759613930137, xgb__max_depth=5, xgb__min_child_weight=7, xgb__n_estimators=543, xgb__reg_alpha=0.5924145688620425, xgb__reg_lambda=0.5929008254399954, xgb__subsample=0.8430179407605753; total time=   0.5s\n",
            "[CV] END xgb__colsample_bytree=0.7465447373174767, xgb__gamma=2.28034992108518, xgb__learning_rate=0.09851759613930137, xgb__max_depth=5, xgb__min_child_weight=7, xgb__n_estimators=543, xgb__reg_alpha=0.5924145688620425, xgb__reg_lambda=0.5929008254399954, xgb__subsample=0.8430179407605753; total time=   0.5s\n",
            "[CV] END xgb__colsample_bytree=0.6682096494749166, xgb__gamma=0.3252579649263976, xgb__learning_rate=0.11488855372533334, xgb__max_depth=6, xgb__min_child_weight=2, xgb__n_estimators=645, xgb__reg_alpha=0.09767211400638387, xgb__reg_lambda=1.8684660530243138, xgb__subsample=0.7760609974958406; total time=   1.1s\n",
            "[CV] END xgb__colsample_bytree=0.6682096494749166, xgb__gamma=0.3252579649263976, xgb__learning_rate=0.11488855372533334, xgb__max_depth=6, xgb__min_child_weight=2, xgb__n_estimators=645, xgb__reg_alpha=0.09767211400638387, xgb__reg_lambda=1.8684660530243138, xgb__subsample=0.7760609974958406; total time=   1.0s\n",
            "[CV] END xgb__colsample_bytree=0.6682096494749166, xgb__gamma=0.3252579649263976, xgb__learning_rate=0.11488855372533334, xgb__max_depth=6, xgb__min_child_weight=2, xgb__n_estimators=645, xgb__reg_alpha=0.09767211400638387, xgb__reg_lambda=1.8684660530243138, xgb__subsample=0.7760609974958406; total time=   1.1s\n",
            "[CV] END xgb__colsample_bytree=0.6682096494749166, xgb__gamma=0.3252579649263976, xgb__learning_rate=0.11488855372533334, xgb__max_depth=6, xgb__min_child_weight=2, xgb__n_estimators=645, xgb__reg_alpha=0.09767211400638387, xgb__reg_lambda=1.8684660530243138, xgb__subsample=0.7760609974958406; total time=   1.3s\n",
            "[CV] END xgb__colsample_bytree=0.6682096494749166, xgb__gamma=0.3252579649263976, xgb__learning_rate=0.11488855372533334, xgb__max_depth=6, xgb__min_child_weight=2, xgb__n_estimators=645, xgb__reg_alpha=0.09767211400638387, xgb__reg_lambda=1.8684660530243138, xgb__subsample=0.7760609974958406; total time=   1.2s\n",
            "[CV] END xgb__colsample_bytree=0.6488152939379115, xgb__gamma=2.475884550556351, xgb__learning_rate=0.02343885211152184, xgb__max_depth=8, xgb__min_child_weight=1, xgb__n_estimators=861, xgb__reg_alpha=0.662522284353982, xgb__reg_lambda=1.123422152178822, xgb__subsample=0.8080272084711243; total time=   1.4s\n",
            "[CV] END xgb__colsample_bytree=0.6488152939379115, xgb__gamma=2.475884550556351, xgb__learning_rate=0.02343885211152184, xgb__max_depth=8, xgb__min_child_weight=1, xgb__n_estimators=861, xgb__reg_alpha=0.662522284353982, xgb__reg_lambda=1.123422152178822, xgb__subsample=0.8080272084711243; total time=   1.4s\n",
            "[CV] END xgb__colsample_bytree=0.6488152939379115, xgb__gamma=2.475884550556351, xgb__learning_rate=0.02343885211152184, xgb__max_depth=8, xgb__min_child_weight=1, xgb__n_estimators=861, xgb__reg_alpha=0.662522284353982, xgb__reg_lambda=1.123422152178822, xgb__subsample=0.8080272084711243; total time=   1.4s\n",
            "[CV] END xgb__colsample_bytree=0.6488152939379115, xgb__gamma=2.475884550556351, xgb__learning_rate=0.02343885211152184, xgb__max_depth=8, xgb__min_child_weight=1, xgb__n_estimators=861, xgb__reg_alpha=0.662522284353982, xgb__reg_lambda=1.123422152178822, xgb__subsample=0.8080272084711243; total time=   1.0s\n",
            "[CV] END xgb__colsample_bytree=0.6488152939379115, xgb__gamma=2.475884550556351, xgb__learning_rate=0.02343885211152184, xgb__max_depth=8, xgb__min_child_weight=1, xgb__n_estimators=861, xgb__reg_alpha=0.662522284353982, xgb__reg_lambda=1.123422152178822, xgb__subsample=0.8080272084711243; total time=   1.0s\n",
            "[CV] END xgb__colsample_bytree=0.8186841117373118, xgb__gamma=0.9242722776276352, xgb__learning_rate=0.11695846277645587, xgb__max_depth=4, xgb__min_child_weight=2, xgb__n_estimators=501, xgb__reg_alpha=0.8948273504276488, xgb__reg_lambda=1.6957999576221703, xgb__subsample=0.9687496940092467; total time=   0.4s\n",
            "[CV] END xgb__colsample_bytree=0.8186841117373118, xgb__gamma=0.9242722776276352, xgb__learning_rate=0.11695846277645587, xgb__max_depth=4, xgb__min_child_weight=2, xgb__n_estimators=501, xgb__reg_alpha=0.8948273504276488, xgb__reg_lambda=1.6957999576221703, xgb__subsample=0.9687496940092467; total time=   0.4s\n",
            "[CV] END xgb__colsample_bytree=0.8186841117373118, xgb__gamma=0.9242722776276352, xgb__learning_rate=0.11695846277645587, xgb__max_depth=4, xgb__min_child_weight=2, xgb__n_estimators=501, xgb__reg_alpha=0.8948273504276488, xgb__reg_lambda=1.6957999576221703, xgb__subsample=0.9687496940092467; total time=   0.4s\n",
            "[CV] END xgb__colsample_bytree=0.8186841117373118, xgb__gamma=0.9242722776276352, xgb__learning_rate=0.11695846277645587, xgb__max_depth=4, xgb__min_child_weight=2, xgb__n_estimators=501, xgb__reg_alpha=0.8948273504276488, xgb__reg_lambda=1.6957999576221703, xgb__subsample=0.9687496940092467; total time=   0.4s\n",
            "[CV] END xgb__colsample_bytree=0.8186841117373118, xgb__gamma=0.9242722776276352, xgb__learning_rate=0.11695846277645587, xgb__max_depth=4, xgb__min_child_weight=2, xgb__n_estimators=501, xgb__reg_alpha=0.8948273504276488, xgb__reg_lambda=1.6957999576221703, xgb__subsample=0.9687496940092467; total time=   0.4s\n",
            "[CV] END xgb__colsample_bytree=0.6353970008207678, xgb__gamma=0.979914312095726, xgb__learning_rate=0.024522728891053808, xgb__max_depth=7, xgb__min_child_weight=2, xgb__n_estimators=352, xgb__reg_alpha=0.5867511656638482, xgb__reg_lambda=2.430510614528276, xgb__subsample=0.8428136990746738; total time=   0.8s\n",
            "[CV] END xgb__colsample_bytree=0.6353970008207678, xgb__gamma=0.979914312095726, xgb__learning_rate=0.024522728891053808, xgb__max_depth=7, xgb__min_child_weight=2, xgb__n_estimators=352, xgb__reg_alpha=0.5867511656638482, xgb__reg_lambda=2.430510614528276, xgb__subsample=0.8428136990746738; total time=   0.8s\n",
            "[CV] END xgb__colsample_bytree=0.6353970008207678, xgb__gamma=0.979914312095726, xgb__learning_rate=0.024522728891053808, xgb__max_depth=7, xgb__min_child_weight=2, xgb__n_estimators=352, xgb__reg_alpha=0.5867511656638482, xgb__reg_lambda=2.430510614528276, xgb__subsample=0.8428136990746738; total time=   0.9s\n",
            "[CV] END xgb__colsample_bytree=0.6353970008207678, xgb__gamma=0.979914312095726, xgb__learning_rate=0.024522728891053808, xgb__max_depth=7, xgb__min_child_weight=2, xgb__n_estimators=352, xgb__reg_alpha=0.5867511656638482, xgb__reg_lambda=2.430510614528276, xgb__subsample=0.8428136990746738; total time=   0.9s\n",
            "[CV] END xgb__colsample_bytree=0.6353970008207678, xgb__gamma=0.979914312095726, xgb__learning_rate=0.024522728891053808, xgb__max_depth=7, xgb__min_child_weight=2, xgb__n_estimators=352, xgb__reg_alpha=0.5867511656638482, xgb__reg_lambda=2.430510614528276, xgb__subsample=0.8428136990746738; total time=   0.8s\n",
            "[CV] END xgb__colsample_bytree=0.7103996728090174, xgb__gamma=1.481367528520412, xgb__learning_rate=0.03652669390630025, xgb__max_depth=3, xgb__min_child_weight=7, xgb__n_estimators=820, xgb__reg_alpha=0.7722447692966574, xgb__reg_lambda=0.8974313630683448, xgb__subsample=0.602208846849441; total time=   0.8s\n",
            "[CV] END xgb__colsample_bytree=0.7103996728090174, xgb__gamma=1.481367528520412, xgb__learning_rate=0.03652669390630025, xgb__max_depth=3, xgb__min_child_weight=7, xgb__n_estimators=820, xgb__reg_alpha=0.7722447692966574, xgb__reg_lambda=0.8974313630683448, xgb__subsample=0.602208846849441; total time=   0.8s\n",
            "[CV] END xgb__colsample_bytree=0.7103996728090174, xgb__gamma=1.481367528520412, xgb__learning_rate=0.03652669390630025, xgb__max_depth=3, xgb__min_child_weight=7, xgb__n_estimators=820, xgb__reg_alpha=0.7722447692966574, xgb__reg_lambda=0.8974313630683448, xgb__subsample=0.602208846849441; total time=   0.8s\n",
            "[CV] END xgb__colsample_bytree=0.7103996728090174, xgb__gamma=1.481367528520412, xgb__learning_rate=0.03652669390630025, xgb__max_depth=3, xgb__min_child_weight=7, xgb__n_estimators=820, xgb__reg_alpha=0.7722447692966574, xgb__reg_lambda=0.8974313630683448, xgb__subsample=0.602208846849441; total time=   0.8s\n",
            "[CV] END xgb__colsample_bytree=0.7103996728090174, xgb__gamma=1.481367528520412, xgb__learning_rate=0.03652669390630025, xgb__max_depth=3, xgb__min_child_weight=7, xgb__n_estimators=820, xgb__reg_alpha=0.7722447692966574, xgb__reg_lambda=0.8974313630683448, xgb__subsample=0.602208846849441; total time=   0.8s\n",
            "[CV] END xgb__colsample_bytree=0.9261845713819337, xgb__gamma=3.534286719238086, xgb__learning_rate=0.09290071680409874, xgb__max_depth=3, xgb__min_child_weight=5, xgb__n_estimators=789, xgb__reg_alpha=0.3584657285442726, xgb__reg_lambda=0.7317381190502594, xgb__subsample=0.9452413703502374; total time=   0.5s\n",
            "[CV] END xgb__colsample_bytree=0.9261845713819337, xgb__gamma=3.534286719238086, xgb__learning_rate=0.09290071680409874, xgb__max_depth=3, xgb__min_child_weight=5, xgb__n_estimators=789, xgb__reg_alpha=0.3584657285442726, xgb__reg_lambda=0.7317381190502594, xgb__subsample=0.9452413703502374; total time=   0.5s\n",
            "[CV] END xgb__colsample_bytree=0.9261845713819337, xgb__gamma=3.534286719238086, xgb__learning_rate=0.09290071680409874, xgb__max_depth=3, xgb__min_child_weight=5, xgb__n_estimators=789, xgb__reg_alpha=0.3584657285442726, xgb__reg_lambda=0.7317381190502594, xgb__subsample=0.9452413703502374; total time=   0.5s\n",
            "[CV] END xgb__colsample_bytree=0.9261845713819337, xgb__gamma=3.534286719238086, xgb__learning_rate=0.09290071680409874, xgb__max_depth=3, xgb__min_child_weight=5, xgb__n_estimators=789, xgb__reg_alpha=0.3584657285442726, xgb__reg_lambda=0.7317381190502594, xgb__subsample=0.9452413703502374; total time=   0.5s\n",
            "[CV] END xgb__colsample_bytree=0.9261845713819337, xgb__gamma=3.534286719238086, xgb__learning_rate=0.09290071680409874, xgb__max_depth=3, xgb__min_child_weight=5, xgb__n_estimators=789, xgb__reg_alpha=0.3584657285442726, xgb__reg_lambda=0.7317381190502594, xgb__subsample=0.9452413703502374; total time=   0.5s\n",
            "[CV] END xgb__colsample_bytree=0.8493192507310232, xgb__gamma=1.654490124263246, xgb__learning_rate=0.026355835028602365, xgb__max_depth=9, xgb__min_child_weight=8, xgb__n_estimators=398, xgb__reg_alpha=0.5912977877077271, xgb__reg_lambda=1.0494435859801283, xgb__subsample=0.8244973703390804; total time=   0.8s\n",
            "[CV] END xgb__colsample_bytree=0.8493192507310232, xgb__gamma=1.654490124263246, xgb__learning_rate=0.026355835028602365, xgb__max_depth=9, xgb__min_child_weight=8, xgb__n_estimators=398, xgb__reg_alpha=0.5912977877077271, xgb__reg_lambda=1.0494435859801283, xgb__subsample=0.8244973703390804; total time=   0.8s\n",
            "[CV] END xgb__colsample_bytree=0.8493192507310232, xgb__gamma=1.654490124263246, xgb__learning_rate=0.026355835028602365, xgb__max_depth=9, xgb__min_child_weight=8, xgb__n_estimators=398, xgb__reg_alpha=0.5912977877077271, xgb__reg_lambda=1.0494435859801283, xgb__subsample=0.8244973703390804; total time=   0.8s\n",
            "[CV] END xgb__colsample_bytree=0.8493192507310232, xgb__gamma=1.654490124263246, xgb__learning_rate=0.026355835028602365, xgb__max_depth=9, xgb__min_child_weight=8, xgb__n_estimators=398, xgb__reg_alpha=0.5912977877077271, xgb__reg_lambda=1.0494435859801283, xgb__subsample=0.8244973703390804; total time=   0.9s\n",
            "[CV] END xgb__colsample_bytree=0.8493192507310232, xgb__gamma=1.654490124263246, xgb__learning_rate=0.026355835028602365, xgb__max_depth=9, xgb__min_child_weight=8, xgb__n_estimators=398, xgb__reg_alpha=0.5912977877077271, xgb__reg_lambda=1.0494435859801283, xgb__subsample=0.8244973703390804; total time=   0.9s\n",
            "[CV] END xgb__colsample_bytree=0.7531707499015159, xgb__gamma=4.858560476945518, xgb__learning_rate=0.10489138242660839, xgb__max_depth=7, xgb__min_child_weight=7, xgb__n_estimators=697, xgb__reg_alpha=0.49379559636439074, xgb__reg_lambda=1.5454656587639881, xgb__subsample=0.7710164073434198; total time=   0.6s\n",
            "[CV] END xgb__colsample_bytree=0.7531707499015159, xgb__gamma=4.858560476945518, xgb__learning_rate=0.10489138242660839, xgb__max_depth=7, xgb__min_child_weight=7, xgb__n_estimators=697, xgb__reg_alpha=0.49379559636439074, xgb__reg_lambda=1.5454656587639881, xgb__subsample=0.7710164073434198; total time=   0.5s\n",
            "[CV] END xgb__colsample_bytree=0.7531707499015159, xgb__gamma=4.858560476945518, xgb__learning_rate=0.10489138242660839, xgb__max_depth=7, xgb__min_child_weight=7, xgb__n_estimators=697, xgb__reg_alpha=0.49379559636439074, xgb__reg_lambda=1.5454656587639881, xgb__subsample=0.7710164073434198; total time=   0.5s\n",
            "[CV] END xgb__colsample_bytree=0.7531707499015159, xgb__gamma=4.858560476945518, xgb__learning_rate=0.10489138242660839, xgb__max_depth=7, xgb__min_child_weight=7, xgb__n_estimators=697, xgb__reg_alpha=0.49379559636439074, xgb__reg_lambda=1.5454656587639881, xgb__subsample=0.7710164073434198; total time=   0.5s\n",
            "[CV] END xgb__colsample_bytree=0.7531707499015159, xgb__gamma=4.858560476945518, xgb__learning_rate=0.10489138242660839, xgb__max_depth=7, xgb__min_child_weight=7, xgb__n_estimators=697, xgb__reg_alpha=0.49379559636439074, xgb__reg_lambda=1.5454656587639881, xgb__subsample=0.7710164073434198; total time=   0.5s\n",
            "[CV] END xgb__colsample_bytree=0.610167650697638, xgb__gamma=0.5394571349665223, xgb__learning_rate=0.023142918568673426, xgb__max_depth=9, xgb__min_child_weight=1, xgb__n_estimators=863, xgb__reg_alpha=0.5632755719763837, xgb__reg_lambda=1.891032172852255, xgb__subsample=0.6557325817623503; total time=   2.5s\n",
            "[CV] END xgb__colsample_bytree=0.610167650697638, xgb__gamma=0.5394571349665223, xgb__learning_rate=0.023142918568673426, xgb__max_depth=9, xgb__min_child_weight=1, xgb__n_estimators=863, xgb__reg_alpha=0.5632755719763837, xgb__reg_lambda=1.891032172852255, xgb__subsample=0.6557325817623503; total time=   2.4s\n",
            "[CV] END xgb__colsample_bytree=0.610167650697638, xgb__gamma=0.5394571349665223, xgb__learning_rate=0.023142918568673426, xgb__max_depth=9, xgb__min_child_weight=1, xgb__n_estimators=863, xgb__reg_alpha=0.5632755719763837, xgb__reg_lambda=1.891032172852255, xgb__subsample=0.6557325817623503; total time=   2.5s\n",
            "[CV] END xgb__colsample_bytree=0.610167650697638, xgb__gamma=0.5394571349665223, xgb__learning_rate=0.023142918568673426, xgb__max_depth=9, xgb__min_child_weight=1, xgb__n_estimators=863, xgb__reg_alpha=0.5632755719763837, xgb__reg_lambda=1.891032172852255, xgb__subsample=0.6557325817623503; total time=   2.7s\n",
            "[CV] END xgb__colsample_bytree=0.610167650697638, xgb__gamma=0.5394571349665223, xgb__learning_rate=0.023142918568673426, xgb__max_depth=9, xgb__min_child_weight=1, xgb__n_estimators=863, xgb__reg_alpha=0.5632755719763837, xgb__reg_lambda=1.891032172852255, xgb__subsample=0.6557325817623503; total time=   2.5s\n",
            "[CV] END xgb__colsample_bytree=0.8417669517111269, xgb__gamma=2.6992054565083654, xgb__learning_rate=0.04030612247347694, xgb__max_depth=7, xgb__min_child_weight=7, xgb__n_estimators=542, xgb__reg_alpha=0.16122128725400442, xgb__reg_lambda=2.359395304685146, xgb__subsample=0.9232481518257668; total time=   0.5s\n",
            "[CV] END xgb__colsample_bytree=0.8417669517111269, xgb__gamma=2.6992054565083654, xgb__learning_rate=0.04030612247347694, xgb__max_depth=7, xgb__min_child_weight=7, xgb__n_estimators=542, xgb__reg_alpha=0.16122128725400442, xgb__reg_lambda=2.359395304685146, xgb__subsample=0.9232481518257668; total time=   0.5s\n",
            "[CV] END xgb__colsample_bytree=0.8417669517111269, xgb__gamma=2.6992054565083654, xgb__learning_rate=0.04030612247347694, xgb__max_depth=7, xgb__min_child_weight=7, xgb__n_estimators=542, xgb__reg_alpha=0.16122128725400442, xgb__reg_lambda=2.359395304685146, xgb__subsample=0.9232481518257668; total time=   0.5s\n",
            "[CV] END xgb__colsample_bytree=0.8417669517111269, xgb__gamma=2.6992054565083654, xgb__learning_rate=0.04030612247347694, xgb__max_depth=7, xgb__min_child_weight=7, xgb__n_estimators=542, xgb__reg_alpha=0.16122128725400442, xgb__reg_lambda=2.359395304685146, xgb__subsample=0.9232481518257668; total time=   0.5s\n",
            "[CV] END xgb__colsample_bytree=0.8417669517111269, xgb__gamma=2.6992054565083654, xgb__learning_rate=0.04030612247347694, xgb__max_depth=7, xgb__min_child_weight=7, xgb__n_estimators=542, xgb__reg_alpha=0.16122128725400442, xgb__reg_lambda=2.359395304685146, xgb__subsample=0.9232481518257668; total time=   0.5s\n",
            "[CV] END xgb__colsample_bytree=0.8533615026041694, xgb__gamma=4.357302950938589, xgb__learning_rate=0.10036720768991146, xgb__max_depth=6, xgb__min_child_weight=4, xgb__n_estimators=630, xgb__reg_alpha=0.32434502100527396, xgb__reg_lambda=0.7441759094013467, xgb__subsample=0.7425191352307899; total time=   0.4s\n",
            "[CV] END xgb__colsample_bytree=0.8533615026041694, xgb__gamma=4.357302950938589, xgb__learning_rate=0.10036720768991146, xgb__max_depth=6, xgb__min_child_weight=4, xgb__n_estimators=630, xgb__reg_alpha=0.32434502100527396, xgb__reg_lambda=0.7441759094013467, xgb__subsample=0.7425191352307899; total time=   0.4s\n",
            "[CV] END xgb__colsample_bytree=0.8533615026041694, xgb__gamma=4.357302950938589, xgb__learning_rate=0.10036720768991146, xgb__max_depth=6, xgb__min_child_weight=4, xgb__n_estimators=630, xgb__reg_alpha=0.32434502100527396, xgb__reg_lambda=0.7441759094013467, xgb__subsample=0.7425191352307899; total time=   0.4s\n",
            "[CV] END xgb__colsample_bytree=0.8533615026041694, xgb__gamma=4.357302950938589, xgb__learning_rate=0.10036720768991146, xgb__max_depth=6, xgb__min_child_weight=4, xgb__n_estimators=630, xgb__reg_alpha=0.32434502100527396, xgb__reg_lambda=0.7441759094013467, xgb__subsample=0.7425191352307899; total time=   0.5s\n",
            "[CV] END xgb__colsample_bytree=0.8533615026041694, xgb__gamma=4.357302950938589, xgb__learning_rate=0.10036720768991146, xgb__max_depth=6, xgb__min_child_weight=4, xgb__n_estimators=630, xgb__reg_alpha=0.32434502100527396, xgb__reg_lambda=0.7441759094013467, xgb__subsample=0.7425191352307899; total time=   0.4s\n",
            "[CV] END xgb__colsample_bytree=0.9627313766183017, xgb__gamma=1.3606612469231765, xgb__learning_rate=0.08476901205413624, xgb__max_depth=3, xgb__min_child_weight=4, xgb__n_estimators=558, xgb__reg_alpha=0.006952130531190703, xgb__reg_lambda=1.5214946051551315, xgb__subsample=0.7669644012595116; total time=   0.5s\n",
            "[CV] END xgb__colsample_bytree=0.9627313766183017, xgb__gamma=1.3606612469231765, xgb__learning_rate=0.08476901205413624, xgb__max_depth=3, xgb__min_child_weight=4, xgb__n_estimators=558, xgb__reg_alpha=0.006952130531190703, xgb__reg_lambda=1.5214946051551315, xgb__subsample=0.7669644012595116; total time=   0.5s\n",
            "[CV] END xgb__colsample_bytree=0.9627313766183017, xgb__gamma=1.3606612469231765, xgb__learning_rate=0.08476901205413624, xgb__max_depth=3, xgb__min_child_weight=4, xgb__n_estimators=558, xgb__reg_alpha=0.006952130531190703, xgb__reg_lambda=1.5214946051551315, xgb__subsample=0.7669644012595116; total time=   0.5s\n",
            "[CV] END xgb__colsample_bytree=0.9627313766183017, xgb__gamma=1.3606612469231765, xgb__learning_rate=0.08476901205413624, xgb__max_depth=3, xgb__min_child_weight=4, xgb__n_estimators=558, xgb__reg_alpha=0.006952130531190703, xgb__reg_lambda=1.5214946051551315, xgb__subsample=0.7669644012595116; total time=   0.5s\n",
            "[CV] END xgb__colsample_bytree=0.9627313766183017, xgb__gamma=1.3606612469231765, xgb__learning_rate=0.08476901205413624, xgb__max_depth=3, xgb__min_child_weight=4, xgb__n_estimators=558, xgb__reg_alpha=0.006952130531190703, xgb__reg_lambda=1.5214946051551315, xgb__subsample=0.7669644012595116; total time=   0.5s\n",
            "[CV] END xgb__colsample_bytree=0.6888431241882921, xgb__gamma=0.599326836668414, xgb__learning_rate=0.0537615171403628, xgb__max_depth=9, xgb__min_child_weight=6, xgb__n_estimators=771, xgb__reg_alpha=0.7030189588951778, xgb__reg_lambda=1.227259204758588, xgb__subsample=0.9887128330883843; total time=   1.1s\n",
            "[CV] END xgb__colsample_bytree=0.6888431241882921, xgb__gamma=0.599326836668414, xgb__learning_rate=0.0537615171403628, xgb__max_depth=9, xgb__min_child_weight=6, xgb__n_estimators=771, xgb__reg_alpha=0.7030189588951778, xgb__reg_lambda=1.227259204758588, xgb__subsample=0.9887128330883843; total time=   1.2s\n",
            "[CV] END xgb__colsample_bytree=0.6888431241882921, xgb__gamma=0.599326836668414, xgb__learning_rate=0.0537615171403628, xgb__max_depth=9, xgb__min_child_weight=6, xgb__n_estimators=771, xgb__reg_alpha=0.7030189588951778, xgb__reg_lambda=1.227259204758588, xgb__subsample=0.9887128330883843; total time=   0.8s\n",
            "[CV] END xgb__colsample_bytree=0.6888431241882921, xgb__gamma=0.599326836668414, xgb__learning_rate=0.0537615171403628, xgb__max_depth=9, xgb__min_child_weight=6, xgb__n_estimators=771, xgb__reg_alpha=0.7030189588951778, xgb__reg_lambda=1.227259204758588, xgb__subsample=0.9887128330883843; total time=   0.9s\n",
            "[CV] END xgb__colsample_bytree=0.6888431241882921, xgb__gamma=0.599326836668414, xgb__learning_rate=0.0537615171403628, xgb__max_depth=9, xgb__min_child_weight=6, xgb__n_estimators=771, xgb__reg_alpha=0.7030189588951778, xgb__reg_lambda=1.227259204758588, xgb__subsample=0.9887128330883843; total time=   0.9s\n",
            "[CV] END xgb__colsample_bytree=0.9849789179768444, xgb__gamma=1.2589114791268208, xgb__learning_rate=0.06972485058923855, xgb__max_depth=3, xgb__min_child_weight=5, xgb__n_estimators=380, xgb__reg_alpha=0.266781014275285, xgb__reg_lambda=2.453229911665306, xgb__subsample=0.7644148053272926; total time=   0.4s\n",
            "[CV] END xgb__colsample_bytree=0.9849789179768444, xgb__gamma=1.2589114791268208, xgb__learning_rate=0.06972485058923855, xgb__max_depth=3, xgb__min_child_weight=5, xgb__n_estimators=380, xgb__reg_alpha=0.266781014275285, xgb__reg_lambda=2.453229911665306, xgb__subsample=0.7644148053272926; total time=   0.4s\n",
            "[CV] END xgb__colsample_bytree=0.9849789179768444, xgb__gamma=1.2589114791268208, xgb__learning_rate=0.06972485058923855, xgb__max_depth=3, xgb__min_child_weight=5, xgb__n_estimators=380, xgb__reg_alpha=0.266781014275285, xgb__reg_lambda=2.453229911665306, xgb__subsample=0.7644148053272926; total time=   0.4s\n",
            "[CV] END xgb__colsample_bytree=0.9849789179768444, xgb__gamma=1.2589114791268208, xgb__learning_rate=0.06972485058923855, xgb__max_depth=3, xgb__min_child_weight=5, xgb__n_estimators=380, xgb__reg_alpha=0.266781014275285, xgb__reg_lambda=2.453229911665306, xgb__subsample=0.7644148053272926; total time=   0.4s\n",
            "[CV] END xgb__colsample_bytree=0.9849789179768444, xgb__gamma=1.2589114791268208, xgb__learning_rate=0.06972485058923855, xgb__max_depth=3, xgb__min_child_weight=5, xgb__n_estimators=380, xgb__reg_alpha=0.266781014275285, xgb__reg_lambda=2.453229911665306, xgb__subsample=0.7644148053272926; total time=   0.4s\n",
            "[CV] END xgb__colsample_bytree=0.6132202931602193, xgb__gamma=1.725356240133415, xgb__learning_rate=0.08343513447013638, xgb__max_depth=8, xgb__min_child_weight=2, xgb__n_estimators=352, xgb__reg_alpha=0.489452760277563, xgb__reg_lambda=2.4713009082212016, xgb__subsample=0.6968221086046001; total time=   0.5s\n",
            "[CV] END xgb__colsample_bytree=0.6132202931602193, xgb__gamma=1.725356240133415, xgb__learning_rate=0.08343513447013638, xgb__max_depth=8, xgb__min_child_weight=2, xgb__n_estimators=352, xgb__reg_alpha=0.489452760277563, xgb__reg_lambda=2.4713009082212016, xgb__subsample=0.6968221086046001; total time=   0.5s\n",
            "[CV] END xgb__colsample_bytree=0.6132202931602193, xgb__gamma=1.725356240133415, xgb__learning_rate=0.08343513447013638, xgb__max_depth=8, xgb__min_child_weight=2, xgb__n_estimators=352, xgb__reg_alpha=0.489452760277563, xgb__reg_lambda=2.4713009082212016, xgb__subsample=0.6968221086046001; total time=   0.5s\n",
            "[CV] END xgb__colsample_bytree=0.6132202931602193, xgb__gamma=1.725356240133415, xgb__learning_rate=0.08343513447013638, xgb__max_depth=8, xgb__min_child_weight=2, xgb__n_estimators=352, xgb__reg_alpha=0.489452760277563, xgb__reg_lambda=2.4713009082212016, xgb__subsample=0.6968221086046001; total time=   0.5s\n",
            "[CV] END xgb__colsample_bytree=0.6132202931602193, xgb__gamma=1.725356240133415, xgb__learning_rate=0.08343513447013638, xgb__max_depth=8, xgb__min_child_weight=2, xgb__n_estimators=352, xgb__reg_alpha=0.489452760277563, xgb__reg_lambda=2.4713009082212016, xgb__subsample=0.6968221086046001; total time=   0.5s\n",
            "[CV] END xgb__colsample_bytree=0.8688542189623514, xgb__gamma=3.8080980766435877, xgb__learning_rate=0.04376375439923997, xgb__max_depth=9, xgb__min_child_weight=6, xgb__n_estimators=579, xgb__reg_alpha=0.4703006344460384, xgb__reg_lambda=2.466846281789686, xgb__subsample=0.7595297769778212; total time=   0.6s\n",
            "[CV] END xgb__colsample_bytree=0.8688542189623514, xgb__gamma=3.8080980766435877, xgb__learning_rate=0.04376375439923997, xgb__max_depth=9, xgb__min_child_weight=6, xgb__n_estimators=579, xgb__reg_alpha=0.4703006344460384, xgb__reg_lambda=2.466846281789686, xgb__subsample=0.7595297769778212; total time=   0.6s\n",
            "[CV] END xgb__colsample_bytree=0.8688542189623514, xgb__gamma=3.8080980766435877, xgb__learning_rate=0.04376375439923997, xgb__max_depth=9, xgb__min_child_weight=6, xgb__n_estimators=579, xgb__reg_alpha=0.4703006344460384, xgb__reg_lambda=2.466846281789686, xgb__subsample=0.7595297769778212; total time=   0.6s\n",
            "[CV] END xgb__colsample_bytree=0.8688542189623514, xgb__gamma=3.8080980766435877, xgb__learning_rate=0.04376375439923997, xgb__max_depth=9, xgb__min_child_weight=6, xgb__n_estimators=579, xgb__reg_alpha=0.4703006344460384, xgb__reg_lambda=2.466846281789686, xgb__subsample=0.7595297769778212; total time=   0.6s\n",
            "[CV] END xgb__colsample_bytree=0.8688542189623514, xgb__gamma=3.8080980766435877, xgb__learning_rate=0.04376375439923997, xgb__max_depth=9, xgb__min_child_weight=6, xgb__n_estimators=579, xgb__reg_alpha=0.4703006344460384, xgb__reg_lambda=2.466846281789686, xgb__subsample=0.7595297769778212; total time=   0.6s\n",
            "[CV] END xgb__colsample_bytree=0.9265727492877536, xgb__gamma=3.9917256249227555, xgb__learning_rate=0.03507175439654295, xgb__max_depth=5, xgb__min_child_weight=6, xgb__n_estimators=763, xgb__reg_alpha=0.040775141554763916, xgb__reg_lambda=1.6817858863764836, xgb__subsample=0.871025744736913; total time=   0.8s\n",
            "[CV] END xgb__colsample_bytree=0.9265727492877536, xgb__gamma=3.9917256249227555, xgb__learning_rate=0.03507175439654295, xgb__max_depth=5, xgb__min_child_weight=6, xgb__n_estimators=763, xgb__reg_alpha=0.040775141554763916, xgb__reg_lambda=1.6817858863764836, xgb__subsample=0.871025744736913; total time=   0.8s\n",
            "[CV] END xgb__colsample_bytree=0.9265727492877536, xgb__gamma=3.9917256249227555, xgb__learning_rate=0.03507175439654295, xgb__max_depth=5, xgb__min_child_weight=6, xgb__n_estimators=763, xgb__reg_alpha=0.040775141554763916, xgb__reg_lambda=1.6817858863764836, xgb__subsample=0.871025744736913; total time=   0.7s\n",
            "[CV] END xgb__colsample_bytree=0.9265727492877536, xgb__gamma=3.9917256249227555, xgb__learning_rate=0.03507175439654295, xgb__max_depth=5, xgb__min_child_weight=6, xgb__n_estimators=763, xgb__reg_alpha=0.040775141554763916, xgb__reg_lambda=1.6817858863764836, xgb__subsample=0.871025744736913; total time=   0.6s\n",
            "[CV] END xgb__colsample_bytree=0.9265727492877536, xgb__gamma=3.9917256249227555, xgb__learning_rate=0.03507175439654295, xgb__max_depth=5, xgb__min_child_weight=6, xgb__n_estimators=763, xgb__reg_alpha=0.040775141554763916, xgb__reg_lambda=1.6817858863764836, xgb__subsample=0.871025744736913; total time=   0.6s\n",
            "[CV] END xgb__colsample_bytree=0.6066351315711425, xgb__gamma=2.560465291496405, xgb__learning_rate=0.0426495775197938, xgb__max_depth=9, xgb__min_child_weight=4, xgb__n_estimators=788, xgb__reg_alpha=0.690937738102466, xgb__reg_lambda=1.2734706926010748, xgb__subsample=0.9746919954946938; total time=   0.7s\n",
            "[CV] END xgb__colsample_bytree=0.6066351315711425, xgb__gamma=2.560465291496405, xgb__learning_rate=0.0426495775197938, xgb__max_depth=9, xgb__min_child_weight=4, xgb__n_estimators=788, xgb__reg_alpha=0.690937738102466, xgb__reg_lambda=1.2734706926010748, xgb__subsample=0.9746919954946938; total time=   0.7s\n",
            "[CV] END xgb__colsample_bytree=0.6066351315711425, xgb__gamma=2.560465291496405, xgb__learning_rate=0.0426495775197938, xgb__max_depth=9, xgb__min_child_weight=4, xgb__n_estimators=788, xgb__reg_alpha=0.690937738102466, xgb__reg_lambda=1.2734706926010748, xgb__subsample=0.9746919954946938; total time=   0.7s\n",
            "[CV] END xgb__colsample_bytree=0.6066351315711425, xgb__gamma=2.560465291496405, xgb__learning_rate=0.0426495775197938, xgb__max_depth=9, xgb__min_child_weight=4, xgb__n_estimators=788, xgb__reg_alpha=0.690937738102466, xgb__reg_lambda=1.2734706926010748, xgb__subsample=0.9746919954946938; total time=   0.7s\n",
            "[CV] END xgb__colsample_bytree=0.6066351315711425, xgb__gamma=2.560465291496405, xgb__learning_rate=0.0426495775197938, xgb__max_depth=9, xgb__min_child_weight=4, xgb__n_estimators=788, xgb__reg_alpha=0.690937738102466, xgb__reg_lambda=1.2734706926010748, xgb__subsample=0.9746919954946938; total time=   0.7s\n",
            "[CV] END xgb__colsample_bytree=0.6550083776583973, xgb__gamma=1.7053317552512925, xgb__learning_rate=0.03134735212405891, xgb__max_depth=9, xgb__min_child_weight=3, xgb__n_estimators=562, xgb__reg_alpha=0.659984046034179, xgb__reg_lambda=2.1344444004024314, xgb__subsample=0.822080324639785; total time=   0.9s\n",
            "[CV] END xgb__colsample_bytree=0.6550083776583973, xgb__gamma=1.7053317552512925, xgb__learning_rate=0.03134735212405891, xgb__max_depth=9, xgb__min_child_weight=3, xgb__n_estimators=562, xgb__reg_alpha=0.659984046034179, xgb__reg_lambda=2.1344444004024314, xgb__subsample=0.822080324639785; total time=   0.9s\n",
            "[CV] END xgb__colsample_bytree=0.6550083776583973, xgb__gamma=1.7053317552512925, xgb__learning_rate=0.03134735212405891, xgb__max_depth=9, xgb__min_child_weight=3, xgb__n_estimators=562, xgb__reg_alpha=0.659984046034179, xgb__reg_lambda=2.1344444004024314, xgb__subsample=0.822080324639785; total time=   0.9s\n",
            "[CV] END xgb__colsample_bytree=0.6550083776583973, xgb__gamma=1.7053317552512925, xgb__learning_rate=0.03134735212405891, xgb__max_depth=9, xgb__min_child_weight=3, xgb__n_estimators=562, xgb__reg_alpha=0.659984046034179, xgb__reg_lambda=2.1344444004024314, xgb__subsample=0.822080324639785; total time=   0.9s\n",
            "[CV] END xgb__colsample_bytree=0.6550083776583973, xgb__gamma=1.7053317552512925, xgb__learning_rate=0.03134735212405891, xgb__max_depth=9, xgb__min_child_weight=3, xgb__n_estimators=562, xgb__reg_alpha=0.659984046034179, xgb__reg_lambda=2.1344444004024314, xgb__subsample=0.822080324639785; total time=   0.8s\n",
            "[CV] END xgb__colsample_bytree=0.8118602313424026, xgb__gamma=1.2092614545022584, xgb__learning_rate=0.029310276780589922, xgb__max_depth=6, xgb__min_child_weight=5, xgb__n_estimators=336, xgb__reg_alpha=0.8826363431893397, xgb__reg_lambda=0.8774142166827588, xgb__subsample=0.7115485410368727; total time=   0.6s\n",
            "[CV] END xgb__colsample_bytree=0.8118602313424026, xgb__gamma=1.2092614545022584, xgb__learning_rate=0.029310276780589922, xgb__max_depth=6, xgb__min_child_weight=5, xgb__n_estimators=336, xgb__reg_alpha=0.8826363431893397, xgb__reg_lambda=0.8774142166827588, xgb__subsample=0.7115485410368727; total time=   0.6s\n",
            "[CV] END xgb__colsample_bytree=0.8118602313424026, xgb__gamma=1.2092614545022584, xgb__learning_rate=0.029310276780589922, xgb__max_depth=6, xgb__min_child_weight=5, xgb__n_estimators=336, xgb__reg_alpha=0.8826363431893397, xgb__reg_lambda=0.8774142166827588, xgb__subsample=0.7115485410368727; total time=   0.7s\n",
            "[CV] END xgb__colsample_bytree=0.8118602313424026, xgb__gamma=1.2092614545022584, xgb__learning_rate=0.029310276780589922, xgb__max_depth=6, xgb__min_child_weight=5, xgb__n_estimators=336, xgb__reg_alpha=0.8826363431893397, xgb__reg_lambda=0.8774142166827588, xgb__subsample=0.7115485410368727; total time=   0.7s\n",
            "[CV] END xgb__colsample_bytree=0.8118602313424026, xgb__gamma=1.2092614545022584, xgb__learning_rate=0.029310276780589922, xgb__max_depth=6, xgb__min_child_weight=5, xgb__n_estimators=336, xgb__reg_alpha=0.8826363431893397, xgb__reg_lambda=0.8774142166827588, xgb__subsample=0.7115485410368727; total time=   0.7s\n",
            "[CV] END xgb__colsample_bytree=0.8801431319891084, xgb__gamma=4.233305711191529, xgb__learning_rate=0.10563242918780925, xgb__max_depth=8, xgb__min_child_weight=8, xgb__n_estimators=886, xgb__reg_alpha=0.9356349942209475, xgb__reg_lambda=2.070681302227887, xgb__subsample=0.8675953018856915; total time=   0.6s\n",
            "[CV] END xgb__colsample_bytree=0.8801431319891084, xgb__gamma=4.233305711191529, xgb__learning_rate=0.10563242918780925, xgb__max_depth=8, xgb__min_child_weight=8, xgb__n_estimators=886, xgb__reg_alpha=0.9356349942209475, xgb__reg_lambda=2.070681302227887, xgb__subsample=0.8675953018856915; total time=   0.6s\n",
            "[CV] END xgb__colsample_bytree=0.8801431319891084, xgb__gamma=4.233305711191529, xgb__learning_rate=0.10563242918780925, xgb__max_depth=8, xgb__min_child_weight=8, xgb__n_estimators=886, xgb__reg_alpha=0.9356349942209475, xgb__reg_lambda=2.070681302227887, xgb__subsample=0.8675953018856915; total time=   0.6s\n",
            "[CV] END xgb__colsample_bytree=0.8801431319891084, xgb__gamma=4.233305711191529, xgb__learning_rate=0.10563242918780925, xgb__max_depth=8, xgb__min_child_weight=8, xgb__n_estimators=886, xgb__reg_alpha=0.9356349942209475, xgb__reg_lambda=2.070681302227887, xgb__subsample=0.8675953018856915; total time=   0.6s\n",
            "[CV] END xgb__colsample_bytree=0.8801431319891084, xgb__gamma=4.233305711191529, xgb__learning_rate=0.10563242918780925, xgb__max_depth=8, xgb__min_child_weight=8, xgb__n_estimators=886, xgb__reg_alpha=0.9356349942209475, xgb__reg_lambda=2.070681302227887, xgb__subsample=0.8675953018856915; total time=   0.6s\n",
            "[CV] END xgb__colsample_bytree=0.8322746485745819, xgb__gamma=1.8614138328087155, xgb__learning_rate=0.11401334424577785, xgb__max_depth=3, xgb__min_child_weight=2, xgb__n_estimators=637, xgb__reg_alpha=0.4856137535862266, xgb__reg_lambda=1.3968482859724947, xgb__subsample=0.9977829850443283; total time=   0.4s\n",
            "[CV] END xgb__colsample_bytree=0.8322746485745819, xgb__gamma=1.8614138328087155, xgb__learning_rate=0.11401334424577785, xgb__max_depth=3, xgb__min_child_weight=2, xgb__n_estimators=637, xgb__reg_alpha=0.4856137535862266, xgb__reg_lambda=1.3968482859724947, xgb__subsample=0.9977829850443283; total time=   0.4s\n",
            "[CV] END xgb__colsample_bytree=0.8322746485745819, xgb__gamma=1.8614138328087155, xgb__learning_rate=0.11401334424577785, xgb__max_depth=3, xgb__min_child_weight=2, xgb__n_estimators=637, xgb__reg_alpha=0.4856137535862266, xgb__reg_lambda=1.3968482859724947, xgb__subsample=0.9977829850443283; total time=   0.4s\n",
            "[CV] END xgb__colsample_bytree=0.8322746485745819, xgb__gamma=1.8614138328087155, xgb__learning_rate=0.11401334424577785, xgb__max_depth=3, xgb__min_child_weight=2, xgb__n_estimators=637, xgb__reg_alpha=0.4856137535862266, xgb__reg_lambda=1.3968482859724947, xgb__subsample=0.9977829850443283; total time=   0.4s\n",
            "[CV] END xgb__colsample_bytree=0.8322746485745819, xgb__gamma=1.8614138328087155, xgb__learning_rate=0.11401334424577785, xgb__max_depth=3, xgb__min_child_weight=2, xgb__n_estimators=637, xgb__reg_alpha=0.4856137535862266, xgb__reg_lambda=1.3968482859724947, xgb__subsample=0.9977829850443283; total time=   0.4s\n",
            "[CV] END xgb__colsample_bytree=0.6703701010709381, xgb__gamma=0.09037681807760434, xgb__learning_rate=0.06938937151834347, xgb__max_depth=6, xgb__min_child_weight=8, xgb__n_estimators=691, xgb__reg_alpha=0.8492234104941779, xgb__reg_lambda=1.8152257846006867, xgb__subsample=0.8273234413341887; total time=   1.1s\n",
            "[CV] END xgb__colsample_bytree=0.6703701010709381, xgb__gamma=0.09037681807760434, xgb__learning_rate=0.06938937151834347, xgb__max_depth=6, xgb__min_child_weight=8, xgb__n_estimators=691, xgb__reg_alpha=0.8492234104941779, xgb__reg_lambda=1.8152257846006867, xgb__subsample=0.8273234413341887; total time=   1.1s\n",
            "[CV] END xgb__colsample_bytree=0.6703701010709381, xgb__gamma=0.09037681807760434, xgb__learning_rate=0.06938937151834347, xgb__max_depth=6, xgb__min_child_weight=8, xgb__n_estimators=691, xgb__reg_alpha=0.8492234104941779, xgb__reg_lambda=1.8152257846006867, xgb__subsample=0.8273234413341887; total time=   1.1s\n",
            "[CV] END xgb__colsample_bytree=0.6703701010709381, xgb__gamma=0.09037681807760434, xgb__learning_rate=0.06938937151834347, xgb__max_depth=6, xgb__min_child_weight=8, xgb__n_estimators=691, xgb__reg_alpha=0.8492234104941779, xgb__reg_lambda=1.8152257846006867, xgb__subsample=0.8273234413341887; total time=   1.1s\n",
            "[CV] END xgb__colsample_bytree=0.6703701010709381, xgb__gamma=0.09037681807760434, xgb__learning_rate=0.06938937151834347, xgb__max_depth=6, xgb__min_child_weight=8, xgb__n_estimators=691, xgb__reg_alpha=0.8492234104941779, xgb__reg_lambda=1.8152257846006867, xgb__subsample=0.8273234413341887; total time=   1.3s\n",
            "[CV] END xgb__colsample_bytree=0.637469907131237, xgb__gamma=1.8385790152971677, xgb__learning_rate=0.046520236768172546, xgb__max_depth=8, xgb__min_child_weight=6, xgb__n_estimators=529, xgb__reg_alpha=0.3930977246667604, xgb__reg_lambda=2.2840931103542266, xgb__subsample=0.8524554503989051; total time=   0.9s\n",
            "[CV] END xgb__colsample_bytree=0.637469907131237, xgb__gamma=1.8385790152971677, xgb__learning_rate=0.046520236768172546, xgb__max_depth=8, xgb__min_child_weight=6, xgb__n_estimators=529, xgb__reg_alpha=0.3930977246667604, xgb__reg_lambda=2.2840931103542266, xgb__subsample=0.8524554503989051; total time=   0.7s\n",
            "[CV] END xgb__colsample_bytree=0.637469907131237, xgb__gamma=1.8385790152971677, xgb__learning_rate=0.046520236768172546, xgb__max_depth=8, xgb__min_child_weight=6, xgb__n_estimators=529, xgb__reg_alpha=0.3930977246667604, xgb__reg_lambda=2.2840931103542266, xgb__subsample=0.8524554503989051; total time=   0.7s\n",
            "[CV] END xgb__colsample_bytree=0.637469907131237, xgb__gamma=1.8385790152971677, xgb__learning_rate=0.046520236768172546, xgb__max_depth=8, xgb__min_child_weight=6, xgb__n_estimators=529, xgb__reg_alpha=0.3930977246667604, xgb__reg_lambda=2.2840931103542266, xgb__subsample=0.8524554503989051; total time=   0.7s\n",
            "[CV] END xgb__colsample_bytree=0.637469907131237, xgb__gamma=1.8385790152971677, xgb__learning_rate=0.046520236768172546, xgb__max_depth=8, xgb__min_child_weight=6, xgb__n_estimators=529, xgb__reg_alpha=0.3930977246667604, xgb__reg_lambda=2.2840931103542266, xgb__subsample=0.8524554503989051; total time=   0.7s\n",
            "[CV] END xgb__colsample_bytree=0.9179245214166594, xgb__gamma=2.5131854655259604, xgb__learning_rate=0.07769038846263591, xgb__max_depth=3, xgb__min_child_weight=5, xgb__n_estimators=815, xgb__reg_alpha=0.02431596643145384, xgb__reg_lambda=1.7909445918143356, xgb__subsample=0.6708442717628196; total time=   0.7s\n",
            "[CV] END xgb__colsample_bytree=0.9179245214166594, xgb__gamma=2.5131854655259604, xgb__learning_rate=0.07769038846263591, xgb__max_depth=3, xgb__min_child_weight=5, xgb__n_estimators=815, xgb__reg_alpha=0.02431596643145384, xgb__reg_lambda=1.7909445918143356, xgb__subsample=0.6708442717628196; total time=   0.7s\n",
            "[CV] END xgb__colsample_bytree=0.9179245214166594, xgb__gamma=2.5131854655259604, xgb__learning_rate=0.07769038846263591, xgb__max_depth=3, xgb__min_child_weight=5, xgb__n_estimators=815, xgb__reg_alpha=0.02431596643145384, xgb__reg_lambda=1.7909445918143356, xgb__subsample=0.6708442717628196; total time=   0.7s\n",
            "[CV] END xgb__colsample_bytree=0.9179245214166594, xgb__gamma=2.5131854655259604, xgb__learning_rate=0.07769038846263591, xgb__max_depth=3, xgb__min_child_weight=5, xgb__n_estimators=815, xgb__reg_alpha=0.02431596643145384, xgb__reg_lambda=1.7909445918143356, xgb__subsample=0.6708442717628196; total time=   0.7s\n",
            "[CV] END xgb__colsample_bytree=0.9179245214166594, xgb__gamma=2.5131854655259604, xgb__learning_rate=0.07769038846263591, xgb__max_depth=3, xgb__min_child_weight=5, xgb__n_estimators=815, xgb__reg_alpha=0.02431596643145384, xgb__reg_lambda=1.7909445918143356, xgb__subsample=0.6708442717628196; total time=   0.7s\n",
            "[CV] END xgb__colsample_bytree=0.9761834337411657, xgb__gamma=4.769642885012937, xgb__learning_rate=0.11148643902204486, xgb__max_depth=5, xgb__min_child_weight=9, xgb__n_estimators=336, xgb__reg_alpha=0.9283185625877254, xgb__reg_lambda=1.3563682966346287, xgb__subsample=0.9866619276174678; total time=   0.3s\n",
            "[CV] END xgb__colsample_bytree=0.9761834337411657, xgb__gamma=4.769642885012937, xgb__learning_rate=0.11148643902204486, xgb__max_depth=5, xgb__min_child_weight=9, xgb__n_estimators=336, xgb__reg_alpha=0.9283185625877254, xgb__reg_lambda=1.3563682966346287, xgb__subsample=0.9866619276174678; total time=   0.3s\n",
            "[CV] END xgb__colsample_bytree=0.9761834337411657, xgb__gamma=4.769642885012937, xgb__learning_rate=0.11148643902204486, xgb__max_depth=5, xgb__min_child_weight=9, xgb__n_estimators=336, xgb__reg_alpha=0.9283185625877254, xgb__reg_lambda=1.3563682966346287, xgb__subsample=0.9866619276174678; total time=   0.3s\n",
            "[CV] END xgb__colsample_bytree=0.9761834337411657, xgb__gamma=4.769642885012937, xgb__learning_rate=0.11148643902204486, xgb__max_depth=5, xgb__min_child_weight=9, xgb__n_estimators=336, xgb__reg_alpha=0.9283185625877254, xgb__reg_lambda=1.3563682966346287, xgb__subsample=0.9866619276174678; total time=   0.3s\n",
            "[CV] END xgb__colsample_bytree=0.9761834337411657, xgb__gamma=4.769642885012937, xgb__learning_rate=0.11148643902204486, xgb__max_depth=5, xgb__min_child_weight=9, xgb__n_estimators=336, xgb__reg_alpha=0.9283185625877254, xgb__reg_lambda=1.3563682966346287, xgb__subsample=0.9866619276174678; total time=   0.3s\n",
            "\n",
            "Best parameters: {'xgb__colsample_bytree': np.float64(0.8404460046972835), 'xgb__gamma': np.float64(3.540362888980227), 'xgb__learning_rate': np.float64(0.022058449429580244), 'xgb__max_depth': 4, 'xgb__min_child_weight': 8, 'xgb__n_estimators': 791, 'xgb__reg_alpha': np.float64(0.9385527090157502), 'xgb__reg_lambda': np.float64(0.5015575316820287), 'xgb__subsample': np.float64(0.996884623716487)}\n",
            "Best CV F1: 0.4106\n",
            "\n",
            "Best threshold for F1 (validation): 0.4736\n",
            "Val Precision/Recall/F1: 0.302/0.769/0.434\n",
            "Precision: 0.293\n",
            "Recall:    0.742\n",
            "F1 Score:  0.421\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.46      0.60      1322\n",
            "           1       0.29      0.74      0.42       396\n",
            "\n",
            "    accuracy                           0.53      1718\n",
            "   macro avg       0.58      0.60      0.51      1718\n",
            "weighted avg       0.73      0.53      0.56      1718\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold, RandomizedSearchCV\n",
        "from sklearn.metrics import (\n",
        "    precision_score, recall_score, f1_score,\n",
        "    classification_report, precision_recall_curve\n",
        ")\n",
        "from catboost import CatBoostClassifier, Pool\n",
        "\n",
        "\n",
        "df = pd.read_csv(\"/content/dataset.csv\")\n",
        "\n",
        "feature_cols = [\n",
        "    'PTS_x','REB_x','AST_x','STL_x','BLK_x','MIN_x',\n",
        "    'PTS_pg_x','REB_pg_x','AST_pg_x','STL_pg_x','BLK_pg_x','MIN_pg_x'\n",
        "]\n",
        "X = df[feature_cols]\n",
        "y = df[\"breakout?\"].astype(int)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "neg, pos = np.bincount(y_train)\n",
        "scale_pos_weight = neg / pos\n",
        "print(f\"Class imbalance ratio (neg/pos): {scale_pos_weight:.2f}\")\n",
        "\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "base_cat = CatBoostClassifier(\n",
        "    task_type=\"GPU\",\n",
        "    devices='0',\n",
        "    eval_metric=\"F1\",\n",
        "    loss_function=\"Logloss\",\n",
        "    random_seed=42,\n",
        "    verbose=False,\n",
        "    class_weights=[1.0, scale_pos_weight]\n",
        ")\n",
        "\n",
        "param_grid = {\n",
        "    \"iterations\": [500, 1000, 1500],\n",
        "    \"depth\": [4, 5, 6, 7, 8],\n",
        "    \"learning_rate\": np.linspace(0.01, 0.2, 10),\n",
        "    \"l2_leaf_reg\": np.linspace(1, 10, 10),\n",
        "    \"border_count\": [32, 64, 128],\n",
        "    \"bagging_temperature\": np.linspace(0, 1, 5),\n",
        "    \"random_strength\": np.linspace(0.5, 5.0, 5)\n",
        "}\n",
        "\n",
        "best_f1 = -1\n",
        "best_params = None\n",
        "\n",
        "\n",
        "for depth in [4, 5, 6, 7]:\n",
        "    for lr in [0.02, 0.05, 0.08, 0.1]:\n",
        "        model = CatBoostClassifier(\n",
        "            task_type=\"GPU\",\n",
        "            devices='0',\n",
        "            iterations=1000,\n",
        "            depth=depth,\n",
        "            learning_rate=lr,\n",
        "            eval_metric=\"F1\",\n",
        "            loss_function=\"Logloss\",\n",
        "            random_seed=42,\n",
        "            verbose=False,\n",
        "            class_weights=[1.0, scale_pos_weight]\n",
        "        )\n",
        "        cv_f1 = []\n",
        "        for train_idx, val_idx in cv.split(X_train, y_train):\n",
        "            X_tr, X_val = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
        "            y_tr, y_val = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
        "            model.fit(X_tr, y_tr, eval_set=(X_val, y_val), early_stopping_rounds=50)\n",
        "            y_val_pred = model.predict(X_val)\n",
        "            f1 = f1_score(y_val, y_val_pred, zero_division=0)\n",
        "            cv_f1.append(f1)\n",
        "        mean_f1 = np.mean(cv_f1)\n",
        "        if mean_f1 > best_f1:\n",
        "            best_f1 = mean_f1\n",
        "            best_params = dict(depth=depth, learning_rate=lr)\n",
        "        print(f\"depth={depth}, lr={lr:.3f}, mean F1={mean_f1:.4f}\")\n",
        "\n",
        "print(f\"\\nBest params: {best_params}, CV F1={best_f1:.4f}\")\n",
        "\n",
        "\n",
        "final_model = CatBoostClassifier(\n",
        "    task_type=\"GPU\",\n",
        "    devices='0',\n",
        "    iterations=1500,\n",
        "    depth=best_params[\"depth\"],\n",
        "    learning_rate=best_params[\"learning_rate\"],\n",
        "    eval_metric=\"F1\",\n",
        "    loss_function=\"Logloss\",\n",
        "    random_seed=42,\n",
        "    verbose=100,\n",
        "    class_weights=[1.0, scale_pos_weight]\n",
        ")\n",
        "\n",
        "X_tr, X_val, y_tr, y_val = train_test_split(\n",
        "    X_train, y_train, test_size=0.2, random_state=42, stratify=y_train\n",
        ")\n",
        "\n",
        "train_pool = Pool(X_tr, y_tr)\n",
        "val_pool = Pool(X_val, y_val)\n",
        "\n",
        "final_model.fit(train_pool, eval_set=val_pool, early_stopping_rounds=75, use_best_model=True, verbose=False)\n",
        "\n",
        "y_val_prob = final_model.predict_proba(X_val)[:, 1]\n",
        "prec, rec, thresh = precision_recall_curve(y_val, y_val_prob)\n",
        "f1_scores = 2 * (prec * rec) / (prec + rec + 1e-12)\n",
        "best_idx = np.nanargmax(f1_scores)\n",
        "best_thresh = float(thresh[max(best_idx, 0)]) if len(thresh) > 0 else 0.5\n",
        "print(f\"\\nOptimal threshold (validation F1): {best_thresh:.4f}\")\n",
        "print(f\"Val Precision/Recall/F1: {prec[best_idx]:.3f}/{rec[best_idx]:.3f}/{f1_scores[best_idx]:.3f}\")\n",
        "\n",
        "y_test_prob = final_model.predict_proba(X_test)[:, 1]\n",
        "y_test_pred = (y_test_prob >= best_thresh).astype(int)\n",
        "\n",
        "precision = precision_score(y_test, y_test_pred, zero_division=0)\n",
        "recall = recall_score(y_test, y_test_pred, zero_division=0)\n",
        "f1 = f1_score(y_test, y_test_pred, zero_division=0)\n",
        "\n",
        "print(f\"Precision: {precision:.3f}\")\n",
        "print(f\"Recall:    {recall:.3f}\")\n",
        "print(f\"F1 Score:  {f1:.3f}\")\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_test_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sXeQGPSKYoAw",
        "outputId": "5a5087b2-28cc-4835-98b2-d044189fbfc2"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class imbalance ratio (neg/pos): 3.34\n",
            "depth=4, lr=0.020, mean F1=0.4219\n",
            "depth=4, lr=0.050, mean F1=0.4223\n",
            "depth=4, lr=0.080, mean F1=0.4218\n",
            "depth=4, lr=0.100, mean F1=0.4180\n",
            "depth=5, lr=0.020, mean F1=0.4259\n",
            "depth=5, lr=0.050, mean F1=0.4280\n",
            "depth=5, lr=0.080, mean F1=0.4258\n",
            "depth=5, lr=0.100, mean F1=0.4221\n",
            "depth=6, lr=0.020, mean F1=0.4203\n",
            "depth=6, lr=0.050, mean F1=0.4200\n",
            "depth=6, lr=0.080, mean F1=0.4179\n",
            "depth=6, lr=0.100, mean F1=0.4192\n",
            "depth=7, lr=0.020, mean F1=0.4287\n",
            "depth=7, lr=0.050, mean F1=0.4258\n",
            "depth=7, lr=0.080, mean F1=0.4257\n",
            "depth=7, lr=0.100, mean F1=0.4198\n",
            "\n",
            "Best params: {'depth': 7, 'learning_rate': 0.02}, CV F1=0.4287\n",
            "\n",
            "Optimal threshold (validation F1): 0.4798\n",
            "Val Precision/Recall/F1: 0.314/0.775/0.447\n",
            "Precision: 0.293\n",
            "Recall:    0.732\n",
            "F1 Score:  0.418\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.47      0.61      1322\n",
            "           1       0.29      0.73      0.42       396\n",
            "\n",
            "    accuracy                           0.53      1718\n",
            "   macro avg       0.57      0.60      0.51      1718\n",
            "weighted avg       0.72      0.53      0.56      1718\n",
            "\n"
          ]
        }
      ]
    }
  ]
}