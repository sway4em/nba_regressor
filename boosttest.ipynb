{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e0bb3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"/content/player_seasons_with_breakouts.csv\")\n",
    "\n",
    "df = df[df[\"E_NET_RATING_PREV\"].notna()].copy()\n",
    "\n",
    "\n",
    "df[\"SEASON_START\"] = df[\"SEASON\"].str.slice(0, 4).astype(int)\n",
    "\n",
    "feature_cols = [\n",
    "    'E_NET_RATING_PREV',\n",
    "    'E_NET_RATING_2YRS_AGO',\n",
    "    'E_OFF_RATING_PREV',\n",
    "    'E_DEF_RATING_PREV',\n",
    "    'TS_PCT_PREV',\n",
    "    'TS_PCT_2YRS_AGO',\n",
    "    'FG_PCT_PREV',\n",
    "    'FG3_PCT_PREV',\n",
    "    'AGE',\n",
    "    'EXPERIENCE'\n",
    "]\n",
    "\n",
    "missing = [c for c in feature_cols if c not in df.columns]\n",
    "\n",
    "\n",
    "train_df = df[df[\"SEASON_START\"] <= 2023].copy()\n",
    "test_df  = df[df[\"SEASON_START\"] >= 2024].copy()\n",
    "\n",
    "# print(f\"Train    rows: {len(train_df):,}\")\n",
    "# print(f\"Test rows:  {len(test_df):,}\")\n",
    "\n",
    "X_train = train_df[feature_cols].copy()\n",
    "y_train = train_df[\"BREAKOUT\"].astype(int)\n",
    "\n",
    "X_test = test_df[feature_cols].copy()\n",
    "y_test = test_df[\"BREAKOUT\"].astype(int)\n",
    "\n",
    "cat_cols = X_train.select_dtypes(include=[\"object\"]).columns.tolist()\n",
    "print(\"catgorical columns:\", cat_cols)\n",
    "\n",
    "if cat_cols:\n",
    "    enc = OrdinalEncoder(handle_unknown=\"use_encoded_value\", unknown_value=-1)\n",
    "    X_train[cat_cols] = enc.fit_transform(X_train[cat_cols])\n",
    "    X_test[cat_cols]  = enc.transform(X_test[cat_cols])\n",
    "\n",
    "X_train = X_train.astype(float)\n",
    "X_test  = X_test.astype(float)\n",
    "#\n",
    "pos_rate = y_train.mean()\n",
    "scale_pos_weight = (1 - pos_rate) / pos_rate\n",
    "\n",
    "model = XGBClassifier(\n",
    "    n_estimators=600,\n",
    "    learning_rate=0.03,\n",
    "    max_depth=5,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    reg_lambda=1.0,\n",
    "    min_child_weight=5,\n",
    "    scale_pos_weight=scale_pos_weight,\n",
    "    objective=\"binary:logistic\",\n",
    "    eval_metric=\"logloss\",\n",
    "    tree_method=\"hist\",\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=[(X_train, y_train)])\n",
    "\n",
    "\n",
    "importances = model.feature_importances_\n",
    "fi_df = pd.DataFrame({\n",
    "    \"feature\": feature_cols,\n",
    "    \"importance\": importances\n",
    "}).sort_values(\"importance\", ascending=False)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
